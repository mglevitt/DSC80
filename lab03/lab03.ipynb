{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSC 80: Lab 03\n",
    "\n",
    "### Due Date: Saturday October 24th, Midnight - 11:59 PM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zoom Lab Hours\n",
    "- Follow instructions on this link: https://docs.google.com/document/d/16qZpPSYhxwQDMcn-lGQjC-J-PzppLevv_mANLt2ko8g/edit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "Much like in DSC 10, this Jupyter Notebook contains the statements of the problems and provides code and markdown cells to display your answers to the problems. Unlike DSC 10, the notebook is *only* for displaying a readable version of your final answers. The coding work will be developed in an accompanying `lab**.py` file, that will be imported into the current notebook.\n",
    "\n",
    "Labs and programming assignments will be graded in (at most) two ways:\n",
    "1. The functions and classes in the accompanying python file will be tested (a la DSC 20),\n",
    "2. The notebook will be graded (for graphs and free response questions).\n",
    "\n",
    "**Do not change the function names in the `*.py` file**\n",
    "- The functions in the `*.py` file are how your assignment is graded, and they are graded by their name. The dictionary at the end of the file (`GRADED FUNCTIONS`) contains the \"grading list\". The final function in the file allows your doctests to check that all the necessary functions exist.\n",
    "- If you changed something you weren't supposed to, just use git to revert!\n",
    "\n",
    "**Tips for working in the Notebook**:\n",
    "- The notebooks serve to present you the questions and give you a place to present your results for later review.\n",
    "- The notebook on *lab assignments* are not graded (only the `.py` file).\n",
    "- Notebooks for PAs will serve as a final report for the assignment, and contain conclusions and answers to open ended questions that are graded.\n",
    "- The notebook serves as a nice environment for 'pre-development' and experimentation before designing your function in your `.py` file.\n",
    "\n",
    "**Tips for developing in the .py file**:\n",
    "- Do not change the function names in the starter code; grading is done using these function names.\n",
    "- Do not change the docstrings in the functions. These are there to tell you if your work is on the right track!\n",
    "- You are encouraged to write your own additional functions to solve the lab! \n",
    "    - Developing in python usually consists of larger files, with many short functions.\n",
    "    - You may write your other functions in an additional `.py` file that you import in `lab**.py` (much like we do in the notebook).\n",
    "- Always document your code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing code from `lab**.py`\n",
    "\n",
    "* We import our `.py` file that's contained in the same directory as this notebook.\n",
    "* We use the `autoreload` notebook extension to make changes to our `lab**.py` file immediately available in our notebook. Without this extension, we would need to restart the notebook kernel to see any changes to `lab**.py` in the notebook.\n",
    "    - `autoreload` is necessary because, upon import, `lab**.py` is compiled to bytecode (in the directory `__pycache__`). Subsequent imports of `lab**` merely import the existing compiled python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lab03 as lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Hypothetically speaking...\n",
    "\n",
    "In this section we'll develop an intuition for the terms and structure of hypothesis testing -- it's nothing to be afraid of!\n",
    "\n",
    "The first step is always to define what you're looking at, create your hypotheses, and set a level of significance.  Once you've done that, you can find a p-value which is related to your test statistic.\n",
    "\n",
    "If all of these words are scary: look at the lecture notebook, the textbook references, and don't forget to think about the real-world meaning of these terms!  The following example describes a real-world scenario, so you can think of it in a normal lens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1: Faulty tires**\n",
    "\n",
    "A tire manufacturer tests whether a set of tires meets the company's performance standards by checking:\n",
    "\n",
    "> In 60 out of 100 tests, if a Honda CRV can come to a complete stop from 60 mph in fewer than 108 feet.\n",
    "\n",
    "That is, 60% of the time, the stopping distance of a car outfitted with generic tires should be less than 108 feet. The factory is wondering if a current run of tires is up to standard, so they choose a random set of tires from the production line to test their performance, and bring the car to a complete stop from 60 mph a total of 100 times. Then they ask:\n",
    "\n",
    "> Are these tires faulty?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following are valid null hypotheses that address the question we are trying to answer, using the data we are given?  Which are valid alternative hypotheses?\n",
    "\n",
    "Outfitted with that set of tires, the car:\n",
    "1. has a 60 mph stopping distance under 108 feet, at least 60% of the time.\n",
    "1. has a 60 mph stopping distance under 108 feet, at most 60% of the time.\n",
    "1. has a 60 mph stopping distance under 108 feet, equal to 60% of the time.\n",
    "1. has at least as short stopping distance to the same car with generic tires, at least 60% of the time.\n",
    "1. has at least as short stopping distance to the same car with generic tires, at most 60% of the time.\n",
    "1. has at least as short stopping distance to the same car with generic tires, roughly 60% of the time.\n",
    "1. is as safe as the car with generic tires.\n",
    "1. causes the car to stop in a shorter distance.\n",
    "\n",
    "\n",
    "Write a function `car_null_hypoth` which takes zero arguments and returns a list of the valid null hypotheses.  \n",
    "Write a function `car_alt_hypoth` which takes zero arguments and returns a list of the valid alternative hypotheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def car_null_hypoth():\n",
    "    \"\"\"\n",
    "    Returns a list of valid null hypotheses.\n",
    "    \n",
    "    :Example:\n",
    "    >>> set(car_null_hypoth()) <= set(range(1,11))\n",
    "    True\n",
    "    \"\"\"\n",
    "    return [3,6, 7]\n",
    "\n",
    "\n",
    "def car_alt_hypoth():\n",
    "    \"\"\"\n",
    "    Returns a list of valid alternative hypotheses.\n",
    "    \n",
    "    :Example:\n",
    "    >>> set(car_alt_hypoth()) <= set(range(1,11))\n",
    "    True\n",
    "    \"\"\"\n",
    "    return [2, 5, 8]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 6, 7]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_null_hypoth()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following are valid test statistics for our question?\n",
    "\n",
    "1. The average number of feet the car took to come to a complete stop in 100 attempts.\n",
    "1. The number of times the car stopped in under 108 feet in 100 attempts.\n",
    "1. The number of attempts it took before the car stopped in under 108 feet.\n",
    "1. The proportion of attempts the car successfully stopped in under 108 feet.\n",
    "\n",
    "Write a function `car_test_stat` which takes zero arguments and returns a list of valid test statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def car_test_stat():\n",
    "    \"\"\"\n",
    "    Returns a list of valid test statistics.\n",
    "    \n",
    "    :Example:\n",
    "    >>> set(car_test_stat()) <= set(range(1,5))\n",
    "    True\n",
    "    \"\"\"\n",
    "    return [1, 2, 4]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value is calculated as how likely it is to find something as extreme or more extreme than our observed test statistic.  To do this, we assume the null hypothesis is true, and then define \"extremeness\" based on the alternative hypothesis.\n",
    "\n",
    "Why don't we just look at the probability of finding our observed test statistic?\n",
    "\n",
    "1. Because our observed test statistic isn't extreme.\n",
    "2. Because the probability of finding our observed test statistic equals the probability of finding something more extreme.\n",
    "3. Because the probability of finding our observed test statistic is essentially zero.\n",
    "4. Because our null hypothesis isn't suggesting equality.\n",
    "5. Because our alternative hypothesis isn't suggesting equality.\n",
    "\n",
    "Write a function `car_p_value` which takes zero arguments and returns the correct reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def car_p_value():\n",
    "    \"\"\"\n",
    "    Returns an integer corresponding to the correct explanation.\n",
    "    \n",
    "    :Example:\n",
    "    >>> car_p_value() in [1,2,3,4,5]\n",
    "    True\n",
    "    \"\"\"\n",
    "    return [2, 3, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping: Google Play Store\n",
    "\n",
    "The questions below analyze a dataset of Google Play Store apps. The dataset has been preprocessed slightly for your convenience.\n",
    "\n",
    "Columns:\n",
    "* `App`: App Name\n",
    "* `Category`: App Category\n",
    "* `Rating`: Average App Rating\n",
    "* `Reviews`: Number of Reviews\n",
    "* `Size`: Size of App\n",
    "* `Installs`: Binned Number of Installs\n",
    "* `Type`: Paid or Free\n",
    "* `Price`: Price of App\n",
    "* `Content Rating`: Age group the app is targeted at\n",
    "* `Last Updated`: Last Updated Date\n",
    "\n",
    "\n",
    "Link: https://www.kaggle.com/lava18/google-play-store-apps\n",
    "\n",
    "**Question 2**\n",
    "\n",
    "First, we'd like to do some basic cleaning to this dataset to better analyze it.\n",
    "In the function `clean_apps`, which takes the Play Store dataset as input, clean as follows and return the cleaned df:\n",
    "* Keep `Reviews` as type int.\n",
    "* Strip all letters from the ends of `Size`, convert all units to unit kilobyte, and convert the column to type float (Hint: all Sizes end in either M (megabyte) or k (kilobyte); a helper function may be useful here).\n",
    "* Strip the '+' from the ends of `Installs`, remove the commas, and convert it to type int.\n",
    "* Since `Type` is binary, change all the 'Free's to 1 and the 'Paid's to 0.\n",
    "* Strip dollar mark in `Price` and convert it to correct numeric data type.\n",
    "* Strip all but the year (e.g. 2018) from `Last Updated` and convert it to type int.\n",
    "\n",
    "Please return a *copy* of the original dataframe; don't alter the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_fp = os.path.join('data', 'googleplaystore.csv')\n",
    "play = pd.read_csv(play_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_apps(df):\n",
    "    '''\n",
    "    >>> fp = os.path.join('data', 'googleplaystore.csv')\n",
    "    >>> df = pd.read_csv(fp)\n",
    "    >>> cleaned = clean_apps(df)\n",
    "    >>> len(cleaned) == len(df)\n",
    "    True\n",
    "    >>> cleaned.Reviews.dtype == int\n",
    "    True\n",
    "    '''\n",
    "    out = df.copy()\n",
    "    out['Reviews'] = df['Reviews'].astype(int)\n",
    "    def clean_size(x):\n",
    "        return x.strip('M').strip('k')\n",
    "    out['Size'] = df['Size'].apply(clean_size)\n",
    "    def clean_installs(x):\n",
    "        return int(x.strip('+').replace(',',''))\n",
    "    out['Installs'] = df['Installs'].apply(clean_installs)\n",
    "    def clean_type(x):\n",
    "        if x == 'Free':\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    out['Type'] = df['Type'].apply(clean_type)\n",
    "    def clean_price(x):\n",
    "        return float(x.strip('$'))\n",
    "    out['Price'] = df['Price'].apply(clean_price)\n",
    "    def clean_lu(x):\n",
    "        return int(x[-4:])\n",
    "    out['Last Updated'] = df['Last Updated'].apply(clean_lu)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>App</th>\n",
       "      <th>Category</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Size</th>\n",
       "      <th>Installs</th>\n",
       "      <th>Type</th>\n",
       "      <th>Price</th>\n",
       "      <th>Content Rating</th>\n",
       "      <th>Last Updated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Photo Editor &amp; Candy Camera &amp; Grid &amp; ScrapBook</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>4.1</td>\n",
       "      <td>159</td>\n",
       "      <td>19</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coloring book moana</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>3.9</td>\n",
       "      <td>967</td>\n",
       "      <td>14</td>\n",
       "      <td>500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U Launcher Lite – FREE Live Cool Themes, Hide ...</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>4.7</td>\n",
       "      <td>87510</td>\n",
       "      <td>8.7</td>\n",
       "      <td>5000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sketch - Draw &amp; Paint</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>4.5</td>\n",
       "      <td>215644</td>\n",
       "      <td>25</td>\n",
       "      <td>50000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Teen</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pixel Draw - Number Art Coloring Book</td>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>4.3</td>\n",
       "      <td>967</td>\n",
       "      <td>2.8</td>\n",
       "      <td>100000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9140</th>\n",
       "      <td>FR Forms</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9141</th>\n",
       "      <td>Sya9a Maroc - FR</td>\n",
       "      <td>FAMILY</td>\n",
       "      <td>4.5</td>\n",
       "      <td>38</td>\n",
       "      <td>53</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9142</th>\n",
       "      <td>Fr. Mike Schmitz Audio Teachings</td>\n",
       "      <td>FAMILY</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9143</th>\n",
       "      <td>Parkinson Exercices FR</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>9.5</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9144</th>\n",
       "      <td>iHoroscope - 2018 Daily Horoscope &amp; Astrology</td>\n",
       "      <td>LIFESTYLE</td>\n",
       "      <td>4.5</td>\n",
       "      <td>398307</td>\n",
       "      <td>19</td>\n",
       "      <td>10000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Everyone</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9145 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    App        Category  \\\n",
       "0        Photo Editor & Candy Camera & Grid & ScrapBook  ART_AND_DESIGN   \n",
       "1                                   Coloring book moana  ART_AND_DESIGN   \n",
       "2     U Launcher Lite – FREE Live Cool Themes, Hide ...  ART_AND_DESIGN   \n",
       "3                                 Sketch - Draw & Paint  ART_AND_DESIGN   \n",
       "4                 Pixel Draw - Number Art Coloring Book  ART_AND_DESIGN   \n",
       "...                                                 ...             ...   \n",
       "9140                                           FR Forms        BUSINESS   \n",
       "9141                                   Sya9a Maroc - FR          FAMILY   \n",
       "9142                   Fr. Mike Schmitz Audio Teachings          FAMILY   \n",
       "9143                             Parkinson Exercices FR         MEDICAL   \n",
       "9144      iHoroscope - 2018 Daily Horoscope & Astrology       LIFESTYLE   \n",
       "\n",
       "      Rating  Reviews Size  Installs  Type  Price Content Rating  Last Updated  \n",
       "0        4.1      159   19     10000     1    0.0       Everyone          2018  \n",
       "1        3.9      967   14    500000     1    0.0       Everyone          2018  \n",
       "2        4.7    87510  8.7   5000000     1    0.0       Everyone          2018  \n",
       "3        4.5   215644   25  50000000     1    0.0           Teen          2018  \n",
       "4        4.3      967  2.8    100000     1    0.0       Everyone          2018  \n",
       "...      ...      ...  ...       ...   ...    ...            ...           ...  \n",
       "9140     NaN        0  9.6        10     1    0.0       Everyone          2016  \n",
       "9141     4.5       38   53      5000     1    0.0       Everyone          2017  \n",
       "9142     5.0        4  3.6       100     1    0.0       Everyone          2018  \n",
       "9143     NaN        3  9.5      1000     1    0.0       Everyone          2017  \n",
       "9144     4.5   398307   19  10000000     1    0.0       Everyone          2018  \n",
       "\n",
       "[9145 rows x 10 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = os.path.join('data', 'googleplaystore.csv')\n",
    "df = pd.read_csv(fp)\n",
    "cleaned = clean_apps(df)\n",
    "cleaned\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2 (Continued)**\n",
    "\n",
    "Now, we can do some basic exploration.\n",
    "\n",
    "In the function `store_info`, find the following using the **cleaned** dataframe:\n",
    "* Find the year with the highest median `Installs`, among all years with at least 100 apps.\n",
    "* Find the `Content Rating` with the highest minimum `Rating`.\n",
    "* Find the `Category` has the highest average price.\n",
    "* Find the `Category` with lowest average rating, among apps that have at least 1000 reviews.\n",
    "\n",
    "and return these values in a list.\n",
    "\n",
    "*Remark:* Note that the last question is asking you to compute the *average of averages* (the 'Rating' column contains the average rating of an app) -- such analyses are prone to occurrences of Simpson's Paradox. Considering apps with at least 1000 reviews helps limit the effect of such [ecological fallacies](https://afraenkel.github.io/practical-data-science/05/understanding-aggregations.html#reversing-aggregations-ecological-fallacies).\n",
    "* You can assume there is no ties.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_info(cleaned):\n",
    "    '''\n",
    "    >>> fp = os.path.join('data', 'googleplaystore.csv')\n",
    "    >>> df = pd.read_csv(fp)\n",
    "    >>> cleaned = clean_apps(df)\n",
    "    >>> info = store_info(cleaned)\n",
    "    >>> len(info)\n",
    "    4\n",
    "    >>> info[2] in cleaned.Category.unique()\n",
    "    True\n",
    "    '''\n",
    "    year_count = cleaned.groupby('Last Updated').count()\n",
    "    filtered_years = year_count[year_count['App'] >= 100].index\n",
    "    filtered_df = cleaned[cleaned['Last Updated'].isin(filtered_years)]\n",
    "    median_installs = filtered_df[['Last Updated','Installs']].groupby('Last Updated').median().idxmax()[0]\n",
    "    \n",
    "    cr_high_min_rating = cleaned[['Content Rating', 'Rating']].groupby('Content Rating').min().idxmax()[0]\n",
    "    \n",
    "    high_price_cat = cleaned[['Category','Price']].groupby('Category').mean().idxmax()[0]\n",
    "    \n",
    "    filtered_df_2 = cleaned[cleaned['Reviews'] >= 1000]\n",
    "    low_avg_rating = filtered_df_2[['Category', 'Rating']].groupby('Category').mean().idxmin()[0]\n",
    "    return [median_installs, cr_high_min_rating, high_price_cat, low_avg_rating]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ART_AND_DESIGN</th>\n",
       "      <td>4.473913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUTO_AND_VEHICLES</th>\n",
       "      <td>4.318519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEAUTY</th>\n",
       "      <td>4.307143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOOKS_AND_REFERENCE</th>\n",
       "      <td>4.398438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUSINESS</th>\n",
       "      <td>4.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COMICS</th>\n",
       "      <td>4.096154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COMMUNICATION</th>\n",
       "      <td>4.212295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATING</th>\n",
       "      <td>3.998925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDUCATION</th>\n",
       "      <td>4.418478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENTERTAINMENT</th>\n",
       "      <td>4.160920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EVENTS</th>\n",
       "      <td>4.358333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAMILY</th>\n",
       "      <td>4.218234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FINANCE</th>\n",
       "      <td>4.324324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FOOD_AND_DRINK</th>\n",
       "      <td>4.177586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAME</th>\n",
       "      <td>4.306675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HEALTH_AND_FITNESS</th>\n",
       "      <td>4.401351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOUSE_AND_HOME</th>\n",
       "      <td>4.183721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LIBRARIES_AND_DEMO</th>\n",
       "      <td>4.108696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LIFESTYLE</th>\n",
       "      <td>4.097345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPS_AND_NAVIGATION</th>\n",
       "      <td>4.236957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEDICAL</th>\n",
       "      <td>4.354667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEWS_AND_MAGAZINES</th>\n",
       "      <td>4.228049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PARENTING</th>\n",
       "      <td>4.355000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PERSONALIZATION</th>\n",
       "      <td>4.324265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PHOTOGRAPHY</th>\n",
       "      <td>4.229480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRODUCTIVITY</th>\n",
       "      <td>4.280916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHOPPING</th>\n",
       "      <td>4.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOCIAL</th>\n",
       "      <td>4.309009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPORTS</th>\n",
       "      <td>4.240854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOOLS</th>\n",
       "      <td>4.199650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAVEL_AND_LOCAL</th>\n",
       "      <td>4.157647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VIDEO_PLAYERS</th>\n",
       "      <td>4.181333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WEATHER</th>\n",
       "      <td>4.293182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Rating\n",
       "Category                     \n",
       "ART_AND_DESIGN       4.473913\n",
       "AUTO_AND_VEHICLES    4.318519\n",
       "BEAUTY               4.307143\n",
       "BOOKS_AND_REFERENCE  4.398438\n",
       "BUSINESS             4.270000\n",
       "COMICS               4.096154\n",
       "COMMUNICATION        4.212295\n",
       "DATING               3.998925\n",
       "EDUCATION            4.418478\n",
       "ENTERTAINMENT        4.160920\n",
       "EVENTS               4.358333\n",
       "FAMILY               4.218234\n",
       "FINANCE              4.324324\n",
       "FOOD_AND_DRINK       4.177586\n",
       "GAME                 4.306675\n",
       "HEALTH_AND_FITNESS   4.401351\n",
       "HOUSE_AND_HOME       4.183721\n",
       "LIBRARIES_AND_DEMO   4.108696\n",
       "LIFESTYLE            4.097345\n",
       "MAPS_AND_NAVIGATION  4.236957\n",
       "MEDICAL              4.354667\n",
       "NEWS_AND_MAGAZINES   4.228049\n",
       "PARENTING            4.355000\n",
       "PERSONALIZATION      4.324265\n",
       "PHOTOGRAPHY          4.229480\n",
       "PRODUCTIVITY         4.280916\n",
       "SHOPPING             4.266667\n",
       "SOCIAL               4.309009\n",
       "SPORTS               4.240854\n",
       "TOOLS                4.199650\n",
       "TRAVEL_AND_LOCAL     4.157647\n",
       "VIDEO_PLAYERS        4.181333\n",
       "WEATHER              4.293182"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = os.path.join('data', 'googleplaystore.csv')\n",
    "df = pd.read_csv(fp)\n",
    "cleaned = clean_apps(df)\n",
    "info = store_info(cleaned)\n",
    "cleaned[cleaned['Reviews'] >= 1000][['Category', 'Rating']].groupby('Category').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming Apps review count by App category\n",
    "\n",
    "A reasonable question that we may ask after cleaning the apps dataset is that how popular each app is. One way of measuring popularity of apps is by studying its review count within their respective category. \n",
    "\n",
    "**Question 3**\n",
    "* Create a function `std_reviews_by_app_cat` that takes in a **cleaned** dataframe and outputs a dataframe with \n",
    "    - the same rows as the input,\n",
    "    - two columns given by `['Category', 'Reviews']`,\n",
    "    - where the `Reviews` columns are *standardized by app category* -- that is, the number of reviews for every app is put into the standard units for the category it belongs to. For a review of standard units, see the [DSC 10 Textbook](https://www.inferentialthinking.com/chapters/15/1/Correlation)\n",
    "    - *Hint*: use the methoc `groupby` and `transform`.\n",
    "* Lastly, create a function `su_and_spread` that returns a list of two items (hard-code your answers):\n",
    "    - Consider the following scenario: half of the apps in the category 'FAMILY' receives ratings of 0 stars while the other\n",
    "    half has rating of 5 stars. Similarly, the ‘MEDICAL' category has half 1-star and half 4-star apps.\n",
    "    Which app would have a higher rating after standarization? The five stars in the family category or the four stars in the\n",
    "    medical one. Answer with the name of the corresponding category ('FAMILY'/'MEDICAL') or use 'equal' if you think both\n",
    "    rating would be the same after standarization. (Don't worry about the uppercase but do be careful with the spelling). \n",
    "    - Which category type has the biggest \"spread\" of review count?\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = lab.clean_apps(play)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_reviews_by_app_cat(cleaned):\n",
    "    \"\"\"\n",
    "    >>> fp = os.path.join('data', 'googleplaystore.csv')\n",
    "    >>> play = pd.read_csv(fp)\n",
    "    >>> clean_play = clean_apps(play)\n",
    "    >>> out = std_reviews_by_app_cat(clean_play)\n",
    "    >>> set(out.columns) == set(['Category', 'Reviews'])\n",
    "    True\n",
    "    >>> np.all(abs(out.select_dtypes(include='number').mean()) < 10**-7)  # standard units should average to 0!\n",
    "    True\n",
    "    \"\"\"\n",
    "    out = cleaned.copy()\n",
    "    means = cleaned[['Category','Reviews']].groupby('Category').mean()\n",
    "    stds = cleaned[['Category','Reviews']].groupby('Category').std()\n",
    "    def standardize(row):\n",
    "        return np.array([row[0],(row[1] - means.loc[row[0],:]['Reviews']) / (stds.loc[row[0],:]['Reviews'])])\n",
    "    out['Reviews'] = cleaned[['Category','Reviews']].transform(standardize, axis = 1)['Reviews']\n",
    "    return out[['Category', 'Reviews']]\n",
    "\n",
    "def su_and_spread():\n",
    "    \"\"\"\n",
    "    >>> out = su_and_spread()\n",
    "    >>> len(out) == 2\n",
    "    True\n",
    "    >>> out[0].lower() in ['medical', 'family', 'equal']\n",
    "    True\n",
    "    >>> out[1] in ['ART_AND_DESIGN', 'AUTO_AND_VEHICLES', 'BEAUTY',\\\n",
    "       'BOOKS_AND_REFERENCE', 'BUSINESS', 'COMICS', 'COMMUNICATION',\\\n",
    "       'DATING', 'EDUCATION', 'ENTERTAINMENT', 'EVENTS', 'FINANCE',\\\n",
    "       'FOOD_AND_DRINK', 'HEALTH_AND_FITNESS', 'HOUSE_AND_HOME',\\\n",
    "       'LIBRARIES_AND_DEMO', 'LIFESTYLE', 'GAME', 'FAMILY', 'MEDICAL',\\\n",
    "       'SOCIAL', 'SHOPPING', 'PHOTOGRAPHY', 'SPORTS', 'TRAVEL_AND_LOCAL',\\\n",
    "       'TOOLS', 'PERSONALIZATION', 'PRODUCTIVITY', 'PARENTING', 'WEATHER',\\\n",
    "       'VIDEO_PLAYERS', 'NEWS_AND_MAGAZINES', 'MAPS_AND_NAVIGATION']\n",
    "    True\n",
    "    \"\"\"\n",
    "    \n",
    "    return ['equal','Game']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>-0.3413694036598642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>-0.32549796076669674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>1.3744553589157202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>3.891375487224039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ART_AND_DESIGN</td>\n",
       "      <td>-0.32549796076669674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9140</th>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>-0.1764708765703538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9141</th>\n",
       "      <td>FAMILY</td>\n",
       "      <td>-0.11223453523315415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9142</th>\n",
       "      <td>FAMILY</td>\n",
       "      <td>-0.11225855690238562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9143</th>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>-0.22383066144932492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9144</th>\n",
       "      <td>LIFESTYLE</td>\n",
       "      <td>2.200101853014516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9145 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Category               Reviews\n",
       "0     ART_AND_DESIGN   -0.3413694036598642\n",
       "1     ART_AND_DESIGN  -0.32549796076669674\n",
       "2     ART_AND_DESIGN    1.3744553589157202\n",
       "3     ART_AND_DESIGN     3.891375487224039\n",
       "4     ART_AND_DESIGN  -0.32549796076669674\n",
       "...              ...                   ...\n",
       "9140        BUSINESS   -0.1764708765703538\n",
       "9141          FAMILY  -0.11223453523315415\n",
       "9142          FAMILY  -0.11225855690238562\n",
       "9143         MEDICAL  -0.22383066144932492\n",
       "9144       LIFESTYLE     2.200101853014516\n",
       "\n",
       "[9145 rows x 2 columns]"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = os.path.join('data', 'googleplaystore.csv')\n",
    "play = pd.read_csv(fp)\n",
    "clean_play = clean_apps(play)\n",
    "out = std_reviews_by_app_cat(clean_play)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category\n",
       "ART_AND_DESIGN         5.090904e+04\n",
       "AUTO_AND_VEHICLES      4.563315e+04\n",
       "BEAUTY                 1.054536e+04\n",
       "BOOKS_AND_REFERENCE    6.850070e+04\n",
       "BUSINESS               8.705346e+04\n",
       "COMICS                 3.641983e+04\n",
       "COMMUNICATION          2.040725e+06\n",
       "DATING                 5.239280e+04\n",
       "EDUCATION              8.654870e+04\n",
       "ENTERTAINMENT          3.031138e+05\n",
       "EVENTS                 6.380886e+03\n",
       "FAMILY                 1.415389e+06\n",
       "FINANCE                1.438728e+05\n",
       "FOOD_AND_DRINK         1.039256e+05\n",
       "GAME                   4.303622e+06\n",
       "HEALTH_AND_FITNESS     8.883747e+04\n",
       "HOUSE_AND_HOME         7.504849e+04\n",
       "LIBRARIES_AND_DEMO     4.451219e+04\n",
       "LIFESTYLE              1.695701e+05\n",
       "MAPS_AND_NAVIGATION    1.440948e+05\n",
       "MEDICAL                1.463978e+04\n",
       "NEWS_AND_MAGAZINES     1.379865e+05\n",
       "PARENTING              8.995770e+04\n",
       "PERSONALIZATION        6.368919e+05\n",
       "PHOTOGRAPHY            9.641880e+05\n",
       "PRODUCTIVITY           6.420081e+05\n",
       "SHOPPING               9.736814e+05\n",
       "SOCIAL                 5.022962e+05\n",
       "SPORTS                 1.026812e+06\n",
       "TOOLS                  1.004547e+06\n",
       "TRAVEL_AND_LOCAL       1.099518e+05\n",
       "VIDEO_PLAYERS          9.160582e+05\n",
       "WEATHER                3.151676e+05\n",
       "Name: Reviews, dtype: float64"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = os.path.join('data', 'googleplaystore.csv')\n",
    "play = pd.read_csv(fp)\n",
    "clean_play = clean_apps(play)\n",
    "\n",
    "clean_play[['Category','Reviews']].groupby('Category').std()['Reviews']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facebook Friends\n",
    "\n",
    "**Question 4**\n",
    "\n",
    "A group of students decided to send out a survey to their Facebook friends. Each student asks 1000 of their friends for their first and last name, the company they currently work at, their job title, their email, and the university they attended. Combine all the data contained in the files `survey*.csv` (within the `responses` folder within the data folder) into a single dataframe. The number of files and the number of rows in each file may vary, so don't hardcode your answers!\n",
    "\n",
    "Create a function `read_survey` which takes in a directory path (containing files `survey*.csv`), and outputs a dataframe with six columns titled: `first name`, `last name`, `current company`, `job title`, `email`, `university` (in that order). \n",
    "\n",
    "*Hint*: You can list the files in a directory using `os.listdir`.\n",
    "\n",
    "*Remark: You may have to do some cleaning to make this possible!*\n",
    "\n",
    "Create a function `com_stats` that takes in in a dataframe and returns a (hardcoded) list containing: \n",
    "- The number of employees at the company that hired the most employees\n",
    "- The number of emails that end in \".edu\"\n",
    "- The job title that has the longest name (there are no ties)\n",
    "- The number of managers (hint: you may want to look through all the job titles to make sure you get all of them!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirname = os.path.join('data', 'responses')\n",
    "lab.read_survey(dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_survey(dirname):\n",
    "    \"\"\"\n",
    "    read_survey combines all the survey*.csv files into a singular DataFrame\n",
    "    :param dirname: directory name where the survey*.csv files are\n",
    "    :returns: a DataFrame containing the combined survey data\n",
    "    :Example:\n",
    "    >>> dirname = os.path.join('data', 'responses')\n",
    "    >>> out = read_survey(dirname)\n",
    "    >>> isinstance(out, pd.DataFrame)\n",
    "    True\n",
    "    >>> len(out)\n",
    "    5000\n",
    "    >>> read_survey('nonexistentfile') # doctest: +ELLIPSIS\n",
    "    Traceback (most recent call last):\n",
    "    ...\n",
    "    FileNotFoundError: ... 'nonexistentfile'\n",
    "    \"\"\"\n",
    "    dirs = os.listdir(dirname)\n",
    "    read_files = []\n",
    "    for file in dirs:\n",
    "        df = pd.read_csv(dirname + '/' + file)\n",
    "        cols = []\n",
    "        for col in df.columns:\n",
    "            cols.append(col.replace('_', ' ').lower())\n",
    "        df.columns = cols\n",
    "        read_files.append(df)\n",
    "              \n",
    "    return pd.concat(read_files)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def com_stats(df):\n",
    "    \"\"\"\n",
    "    com_stats \n",
    "    :param df: a DataFrame containing the combined survey data\n",
    "    :returns: a hardcoded list of answers to the problems in the notebook\n",
    "    :Example:\n",
    "    >>> dirname = os.path.join('data', 'responses')\n",
    "    >>> df = read_survey(dirname)\n",
    "    >>> out = com_stats(df)\n",
    "    >>> len(out)\n",
    "    4\n",
    "    >>> isinstance(out[0], int)\n",
    "    True\n",
    "    >>> isinstance(out[2], str)\n",
    "    True\n",
    "    \"\"\"\n",
    "    out1 = max(df.groupby('current company').size())\n",
    "    def check_edu(email):\n",
    "        temp = str(email)\n",
    "        if temp[-4:] == '.edu':\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    out2 = len(list(filter(check_edu, df['email'])))\n",
    "    max_out3 = 0\n",
    "    out3 = ''\n",
    "    out4 = 0\n",
    "    for tit in df['job title']:\n",
    "        temp = len(str(tit))\n",
    "        if temp > max_out3:\n",
    "            max_out3 = temp\n",
    "            out3 = str(tit)\n",
    "        fixed = str(tit).lower()\n",
    "        if 'manager' in fixed:\n",
    "            out4 += 1\n",
    "    \n",
    "    return [out1, out2, out3, out4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 253, 'Business Systems Development Analyst', 369]"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirname = os.path.join('data', 'responses')\n",
    "df = read_survey(dirname)\n",
    "out = com_stats(df)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Data\n",
    "**Question 5**\n",
    "\n",
    "Every week, a professor sends out an extra credit survey asking for students' favorite things (animals, movies, etc). \n",
    "- Each student who has completed at least 75% of the surveys receives 5 points of extra credit.\n",
    "- If at least 90% of the class answers at least one of the questions (ex. favorite animal), *everyone* in the class receives 1 point of extra credit. This overall class extra credit only applies once (ex. If 95% of students answer favorite color and 91% answer favorite animal, the entire class still only receives 1 extra point as a class).\n",
    "\n",
    "Create a function `combine_surveys` which takes in a directory path (containing files `favorite*.csv`) and combines all of the survey data into one DataFrame, indexed by student ID (a value 1 - 1000).\n",
    "\n",
    "Create a function `check_credit` which takes in a DataFrame with the combined survey data and outputs a DataFrame of the names of students and how many extra credit points they would receive, indexed by their ID (a value 1-1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirname = os.path.join('data', 'extra-credit-surveys')\n",
    "df = lab.combine_surveys(dirname)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_surveys(dirname):\n",
    "    \"\"\"\n",
    "    combine_surveys takes in a directory path \n",
    "    (containing files favorite*.csv) and combines \n",
    "    all of the survey data into one DataFrame, \n",
    "    indexed by student ID (a value 0 - 1000).\n",
    "\n",
    "    :Example:\n",
    "    >>> dirname = os.path.join('data', 'extra-credit-surveys')\n",
    "    >>> out = combine_surveys(dirname)\n",
    "    >>> isinstance(out, pd.DataFrame)\n",
    "    True\n",
    "    >>> out.shape\n",
    "    (1000, 6)\n",
    "    >>> combine_surveys('nonexistentfile') # doctest: +ELLIPSIS\n",
    "    Traceback (most recent call last):\n",
    "    ...\n",
    "    FileNotFoundError: ... 'nonexistentfile'\n",
    "    \"\"\"\n",
    "    \n",
    "    directory = os.listdir(dirname)\n",
    "    dfs = []\n",
    "    for file in directory:\n",
    "        df = pd.read_csv(dirname + \"/\" + file)  \n",
    "        dfs.append(df.set_index('id'))\n",
    "    return pd.concat(dfs, sort=True, axis=1)\n",
    "    \n",
    "\n",
    "\n",
    "def check_credit(df):\n",
    "    \"\"\"\n",
    "    check_credit takes in a DataFrame with the \n",
    "    combined survey data and outputs a DataFrame \n",
    "    of the names of students and how many extra credit \n",
    "    points they would receive, indexed by their ID (a value 0-1000)\n",
    "\n",
    "    :Example:\n",
    "    >>> dirname = os.path.join('data', 'extra-credit-surveys')\n",
    "    >>> df = combine_surveys(dirname)\n",
    "    >>> out = check_credit(df)\n",
    "    >>> out.shape\n",
    "    (1000, 2)\n",
    "    \"\"\"\n",
    "    def check_student(student):\n",
    "        num_surveys_not_done = student.isnull().sum()\n",
    "        if num_surveys_not_done > 1:\n",
    "            return 0 \n",
    "        else:\n",
    "            return 5\n",
    "    def check_class(df):\n",
    "        bool_ar = (df.isnull().sum().values / df.shape[0]) <= .10\n",
    "        if True in bool_ar:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    df['extra credit'] = df.apply(check_student, axis=1)\n",
    "    if check_class(df) == True:\n",
    "        df['extra credit'] = df['extra credit'] + 1\n",
    "    return df[['name', 'extra credit']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>movie</th>\n",
       "      <th>genre</th>\n",
       "      <th>animal</th>\n",
       "      <th>plant</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Myrtia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(no genres listed)</td>\n",
       "      <td>Long-crested hawk eagle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nathanil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>Euro wallaby</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Khaki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Joni</td>\n",
       "      <td>Glass-blower's Children, The (Glasblåsarns barn)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brown brocket</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prentice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(no genres listed)</td>\n",
       "      <td>Peccary, white-lipped</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Claudette</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Capuchin, brown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fuscia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Addie</td>\n",
       "      <td>Kung Phooey!</td>\n",
       "      <td>Horror|Mystery|Sci-Fi</td>\n",
       "      <td>Eland, common</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Purple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Valaria</td>\n",
       "      <td>Angel Heart</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Agouti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Gunilla</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shelduck, european</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Zitella</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Maroon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>Jammal</td>\n",
       "      <td>Zathura</td>\n",
       "      <td>Drama</td>\n",
       "      <td>African porcupine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           name                                             movie  \\\n",
       "id                                                                  \n",
       "1        Myrtia                                               NaN   \n",
       "2      Nathanil                                               NaN   \n",
       "3          Joni  Glass-blower's Children, The (Glasblåsarns barn)   \n",
       "4      Prentice                                               NaN   \n",
       "5     Claudette                                               NaN   \n",
       "...         ...                                               ...   \n",
       "996       Addie                                      Kung Phooey!   \n",
       "997     Valaria                                       Angel Heart   \n",
       "998     Gunilla                                               NaN   \n",
       "999     Zitella                                               NaN   \n",
       "1000     Jammal                                           Zathura   \n",
       "\n",
       "                      genre                   animal plant   color  \n",
       "id                                                                  \n",
       "1        (no genres listed)  Long-crested hawk eagle   NaN     Red  \n",
       "2               Documentary             Euro wallaby   NaN   Khaki  \n",
       "3                       NaN            Brown brocket   NaN     Red  \n",
       "4        (no genres listed)    Peccary, white-lipped   NaN  Yellow  \n",
       "5                       NaN          Capuchin, brown   NaN  Fuscia  \n",
       "...                     ...                      ...   ...     ...  \n",
       "996   Horror|Mystery|Sci-Fi            Eland, common   NaN  Purple  \n",
       "997                     NaN                   Agouti   NaN    Blue  \n",
       "998                     NaN       Shelduck, european   NaN     NaN  \n",
       "999                  Comedy                      NaN   NaN  Maroon  \n",
       "1000                  Drama        African porcupine   NaN     Red  \n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirname = os.path.join('data', 'extra-credit-surveys')\n",
    "out = combine_surveys(dirname)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>extra credit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Myrtia</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nathanil</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Joni</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prentice</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Claudette</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Addie</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Valaria</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Gunilla</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Zitella</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>Jammal</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           name  extra credit\n",
       "id                           \n",
       "1        Myrtia             1\n",
       "2      Nathanil             1\n",
       "3          Joni             1\n",
       "4      Prentice             1\n",
       "5     Claudette             1\n",
       "...         ...           ...\n",
       "996       Addie             6\n",
       "997     Valaria             1\n",
       "998     Gunilla             1\n",
       "999     Zitella             1\n",
       "1000     Jammal             6\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirname = os.path.join('data', 'extra-credit-surveys')\n",
    "df = combine_surveys(dirname)\n",
    "out = check_credit(df)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining pets and owners\n",
    "\n",
    "**Question 6**\n",
    "\n",
    "You are analyzing data from a veterinarian clinic. The datasets contain several types of information from the clinic, including its customers (pet owners), pets, and available procedures and history. The column names are self-explanatory. These dataframes are provided to you:\n",
    "-  `owners` stores the customer information, where every `OwnerID` is unique (verify yourself).\n",
    "-  `pets` stores the pet information. Each pet belongs to a customer in `owners`.\n",
    "-  `procedure_detail` contains a catalog of procedures that are offered by the clinic.\n",
    "-  `procedure_history` has procedure records. Each procedure is given to a pet in `pets`.\n",
    "\n",
    "You want to answer the following questions:\n",
    "\n",
    "1. What is the most popular Procedure Type for all of the pets we have in our `pets` dataset? Note that some pets are registered but haven't had any procedure performed. Also, some pets that have had procedures done, are not registered in `pets`. Create a function `most_popular_procedure` that takes in `pets`, `procedure_history` and returns the name of the most popular Procedure Type as a string.\n",
    " \n",
    "2. What is the name of each customer's pet(s)? Create a function `pet_name_by_owner` that takes in `owners`, `pets` and returns a Series that holds the pet name (as a string) indexed by owner's (first) name. If an owner has multiple pets, the corresponding value should be a list of names as strings.\n",
    "\n",
    "3. For each city that had owners who had their pets in our procedure history, how much does the city spend in total on procedures? Create a function `total_cost_per_city` that returns a Series that contains the sum of money that a city has spent on pets' procedures, indexed by `City`. Hint: think of what makes a procedure unique in the context of this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "owners_fp = os.path.join('data', 'pets', 'Owners.csv')\n",
    "pets_fp = os.path.join('data', 'pets', 'Pets.csv')\n",
    "procedure_detail_fp = os.path.join('data', 'pets', 'ProceduresDetails.csv')\n",
    "procedure_history_fp = os.path.join('data', 'pets', 'ProceduresHistory.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "owners = pd.read_csv(owners_fp)\n",
    "pets = pd.read_csv(pets_fp)\n",
    "procedure_detail = pd.read_csv(procedure_detail_fp)\n",
    "procedure_history = pd.read_csv(procedure_history_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PetID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Kind</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>OwnerID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>J6-8562</td>\n",
       "      <td>Blackie</td>\n",
       "      <td>Dog</td>\n",
       "      <td>male</td>\n",
       "      <td>11</td>\n",
       "      <td>5168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q0-2001</td>\n",
       "      <td>Roomba</td>\n",
       "      <td>Cat</td>\n",
       "      <td>male</td>\n",
       "      <td>9</td>\n",
       "      <td>5508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M0-2904</td>\n",
       "      <td>Simba</td>\n",
       "      <td>Cat</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>3086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R3-7551</td>\n",
       "      <td>Keller</td>\n",
       "      <td>Parrot</td>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>7908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P2-7342</td>\n",
       "      <td>Cuddles</td>\n",
       "      <td>Dog</td>\n",
       "      <td>male</td>\n",
       "      <td>13</td>\n",
       "      <td>4378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>U8-6473</td>\n",
       "      <td>Biscuit</td>\n",
       "      <td>Dog</td>\n",
       "      <td>female</td>\n",
       "      <td>3</td>\n",
       "      <td>1070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>I5-4893</td>\n",
       "      <td>Cookie</td>\n",
       "      <td>Cat</td>\n",
       "      <td>female</td>\n",
       "      <td>3</td>\n",
       "      <td>7340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Q8-0954</td>\n",
       "      <td>Lakshmi</td>\n",
       "      <td>Cat</td>\n",
       "      <td>female</td>\n",
       "      <td>7</td>\n",
       "      <td>9385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>N0-9539</td>\n",
       "      <td>Swiffer</td>\n",
       "      <td>Cat</td>\n",
       "      <td>male</td>\n",
       "      <td>14</td>\n",
       "      <td>9365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>S5-5938</td>\n",
       "      <td>Taz</td>\n",
       "      <td>Dog</td>\n",
       "      <td>male</td>\n",
       "      <td>6</td>\n",
       "      <td>9427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PetID     Name    Kind  Gender  Age  OwnerID\n",
       "0   J6-8562  Blackie     Dog    male   11     5168\n",
       "1   Q0-2001   Roomba     Cat    male    9     5508\n",
       "2   M0-2904    Simba     Cat    male    1     3086\n",
       "3   R3-7551   Keller  Parrot  female    2     7908\n",
       "4   P2-7342  Cuddles     Dog    male   13     4378\n",
       "..      ...      ...     ...     ...  ...      ...\n",
       "95  U8-6473  Biscuit     Dog  female    3     1070\n",
       "96  I5-4893   Cookie     Cat  female    3     7340\n",
       "97  Q8-0954  Lakshmi     Cat  female    7     9385\n",
       "98  N0-9539  Swiffer     Cat    male   14     9365\n",
       "99  S5-5938      Taz     Dog    male    6     9427\n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab.pet_name_by_owner(owners, pets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_popular_procedure(pets, procedure_history):\n",
    "    \"\"\"\n",
    "    What is the most popular Procedure Type for all of the pets we have in our `pets` dataset?\n",
    "    :Example:\n",
    "    >>> pets_fp = os.path.join('data', 'pets', 'Pets.csv')\n",
    "    >>> procedure_history_fp = os.path.join('data', 'pets', 'ProceduresHistory.csv')\n",
    "    >>> pets = pd.read_csv(pets_fp)\n",
    "    >>> procedure_history = pd.read_csv(procedure_history_fp)\n",
    "    >>> out = most_popular_procedure(pets, procedure_history)\n",
    "    >>> isinstance(out,str)\n",
    "    True\n",
    "    \"\"\"\n",
    "    merged_df = pets.merge(procedure_history, how = 'inner',on = 'PetID')\n",
    "    return merged_df.groupby('ProcedureType').count().idxmax()[0]\n",
    "\n",
    "\n",
    "def pet_name_by_owner(owners, pets):\n",
    "    \"\"\"\n",
    "    pet names by owner\n",
    "\n",
    "    :Example:\n",
    "    >>> owners_fp = os.path.join('data', 'pets', 'Owners.csv')\n",
    "    >>> pets_fp = os.path.join('data', 'pets', 'Pets.csv')\n",
    "    >>> owners = pd.read_csv(owners_fp)\n",
    "    >>> pets = pd.read_csv(pets_fp)\n",
    "    >>> out = pet_name_by_owner(owners, pets)\n",
    "    >>> len(out) == len(owners)\n",
    "    True\n",
    "    >>> 'Sarah' in out.index\n",
    "    True\n",
    "    >>> 'Cookie' in out.values\n",
    "    True\n",
    "    \"\"\"\n",
    "    def list_func(pets):\n",
    "        pets = list(pets)\n",
    "        if len(pets) == 1:\n",
    "            return pets[0]\n",
    "        else:\n",
    "            return pets\n",
    "    owners_ID_pets = pets.groupby('OwnerID')['Name'].apply(list_func)\n",
    "    merged_df = owners.merge(owners_ID_pets, how = 'inner', on = 'OwnerID')[['Name_x','Name_y']]\n",
    "    return merged_df.set_index(['Name_x'])['Name_y']\n",
    "\n",
    "\n",
    "def total_cost_per_city(owners, pets, procedure_history, procedure_detail):\n",
    "    \"\"\"\n",
    "    total cost per city\n",
    "​\n",
    "    :Example:\n",
    "    >>> owners_fp = os.path.join('data', 'pets', 'Owners.csv')\n",
    "    >>> pets_fp = os.path.join('data', 'pets', 'Pets.csv')\n",
    "    >>> procedure_detail_fp = os.path.join('data', 'pets', 'ProceduresDetails.csv')\n",
    "    >>> procedure_history_fp = os.path.join('data', 'pets', 'ProceduresHistory.csv')\n",
    "    >>> owners = pd.read_csv(owners_fp)\n",
    "    >>> pets = pd.read_csv(pets_fp)\n",
    "    >>> procedure_detail = pd.read_csv(procedure_detail_fp)\n",
    "    >>> procedure_history = pd.read_csv(procedure_history_fp)\n",
    "    >>> out = total_cost_per_city(owners, pets, procedure_history, procedure_detail)\n",
    "    >>> set(out.index) <= set(owners['City'])\n",
    "    True\n",
    "    \"\"\"\n",
    "    merged_df = pets.merge(owners, how = 'inner', on = 'OwnerID').merge(procedure_history, how = 'inner', on = 'PetID').merge(procedure_detail, how = 'inner', on = 'ProcedureType')\n",
    "    return merged_df.groupby('City').sum()['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City\n",
       "Ann Arbor            7705\n",
       "Center Line            85\n",
       "Commerce               85\n",
       "Detroit              1767\n",
       "East Lansing         1767\n",
       "Farmington Hills       40\n",
       "Flint                  40\n",
       "Grand Rapids        19921\n",
       "Kalamazoo              40\n",
       "Lansing               255\n",
       "Livonia                85\n",
       "Marquette             425\n",
       "Michigan Center        85\n",
       "Plymouth               85\n",
       "Pontiac               255\n",
       "Roseville              85\n",
       "Saint Charles          85\n",
       "Southfield            465\n",
       "Warren                 85\n",
       "Wayne                  85\n",
       "Name: Price, dtype: int64"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "owners_fp = os.path.join('data', 'pets', 'Owners.csv')\n",
    "pets_fp = os.path.join('data', 'pets', 'Pets.csv')\n",
    "procedure_detail_fp = os.path.join('data', 'pets', 'ProceduresDetails.csv')\n",
    "procedure_history_fp = os.path.join('data', 'pets', 'ProceduresHistory.csv')\n",
    "owners = pd.read_csv(owners_fp)\n",
    "pets = pd.read_csv(pets_fp)\n",
    "procedure_detail = pd.read_csv(procedure_detail_fp)\n",
    "procedure_history = pd.read_csv(procedure_history_fp)\n",
    "out = total_cost_per_city(owners, pets, procedure_history, procedure_detail)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name_x\n",
       "Debbie              Biscuit\n",
       "John                Biscuit\n",
       "Connie              Biscuit\n",
       "Lena                Biscuit\n",
       "Jessica             Biscuit\n",
       "                 ...       \n",
       "Robert                  Taz\n",
       "Daniel              Scooter\n",
       "Alden               Scooter\n",
       "Gary       [Scooter, Daisy]\n",
       "Joseph              Blackie\n",
       "Name: Name_y, Length: 89, dtype: object"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "owners_fp = os.path.join('data', 'pets', 'Owners.csv')\n",
    "pets_fp = os.path.join('data', 'pets', 'Pets.csv')\n",
    "owners = pd.read_csv(owners_fp)\n",
    "pets = pd.read_csv(pets_fp)\n",
    "out = pet_name_by_owner(owners, pets)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VACCINATIONS'"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pets_fp = os.path.join('data', 'pets', 'Pets.csv')\n",
    "procedure_history_fp = os.path.join('data', 'pets', 'ProceduresHistory.csv')\n",
    "pets = pd.read_csv(pets_fp)\n",
    "procedure_history = pd.read_csv(procedure_history_fp)\n",
    "out = most_popular_procedure(pets, procedure_history)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProcedureType</th>\n",
       "      <th>ProcedureSubCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OFFICE FEES</td>\n",
       "      <td>1</td>\n",
       "      <td>Office Call</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OFFICE FEES</td>\n",
       "      <td>2</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OFFICE FEES</td>\n",
       "      <td>3</td>\n",
       "      <td>Reck</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GROOMING</td>\n",
       "      <td>1</td>\n",
       "      <td>Bath</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GROOMING</td>\n",
       "      <td>2</td>\n",
       "      <td>Flea Dip</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GROOMING</td>\n",
       "      <td>3</td>\n",
       "      <td>Flea Spray</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VACCINATIONS</td>\n",
       "      <td>1</td>\n",
       "      <td>Galaxie (DHLPP)</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>VACCINATIONS</td>\n",
       "      <td>2</td>\n",
       "      <td>Leukemia</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>VACCINATIONS</td>\n",
       "      <td>3</td>\n",
       "      <td>Lyme</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>VACCINATIONS</td>\n",
       "      <td>4</td>\n",
       "      <td>PCR</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>VACCINATIONS</td>\n",
       "      <td>5</td>\n",
       "      <td>Rabies</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>VACCINATIONS</td>\n",
       "      <td>6</td>\n",
       "      <td>Bordetella</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HOSPITALIZATION</td>\n",
       "      <td>1</td>\n",
       "      <td>All Hospitalization</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ORTHOPEDIC</td>\n",
       "      <td>1</td>\n",
       "      <td>Amput. per lim thor.</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ORTHOPEDIC</td>\n",
       "      <td>2</td>\n",
       "      <td>Casting</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ORTHOPEDIC</td>\n",
       "      <td>3</td>\n",
       "      <td>Re-Casting</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ORTHOPEDIC</td>\n",
       "      <td>4</td>\n",
       "      <td>Fem. head Ostec.</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ORTHOPEDIC</td>\n",
       "      <td>5</td>\n",
       "      <td>Lx Patella Repair</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ORTHOPEDIC</td>\n",
       "      <td>6</td>\n",
       "      <td>Metamason Splint</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ORTHOPEDIC</td>\n",
       "      <td>7</td>\n",
       "      <td>Pinning-I.M.</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ORTHOPEDIC</td>\n",
       "      <td>8</td>\n",
       "      <td>Pin Removal</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ORTHOPEDIC</td>\n",
       "      <td>9</td>\n",
       "      <td>Cast Removal</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>GENERAL SURGERIES</td>\n",
       "      <td>1</td>\n",
       "      <td>Anal Gland Caut</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>GENERAL SURGERIES</td>\n",
       "      <td>2</td>\n",
       "      <td>Aural Hematoma</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>GENERAL SURGERIES</td>\n",
       "      <td>3</td>\n",
       "      <td>Declaw</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>GENERAL SURGERIES</td>\n",
       "      <td>4</td>\n",
       "      <td>Dissolvable Suture</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>GENERAL SURGERIES</td>\n",
       "      <td>5</td>\n",
       "      <td>Ear Crop</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>GENERAL SURGERIES</td>\n",
       "      <td>6</td>\n",
       "      <td>Gastric Torsion</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>GENERAL SURGERIES</td>\n",
       "      <td>7</td>\n",
       "      <td>Hernia</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>GENERAL SURGERIES</td>\n",
       "      <td>8</td>\n",
       "      <td>Umbilical</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>GENERAL SURGERIES</td>\n",
       "      <td>9</td>\n",
       "      <td>Perineal</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>GENERAL SURGERIES</td>\n",
       "      <td>10</td>\n",
       "      <td>Unilat Inquinal</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>GENERAL SURGERIES</td>\n",
       "      <td>11</td>\n",
       "      <td>Intestinal Anas</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>GENERAL SURGERIES</td>\n",
       "      <td>12</td>\n",
       "      <td>Open Chest Surgery</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>GENERAL SURGERIES</td>\n",
       "      <td>13</td>\n",
       "      <td>Perineal Adenoma</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>GENERAL SURGERIES</td>\n",
       "      <td>14</td>\n",
       "      <td>Peritoneal Lavage</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>GENERAL SURGERIES</td>\n",
       "      <td>15</td>\n",
       "      <td>Pyloric Stenosis</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>GENERAL SURGERIES</td>\n",
       "      <td>16</td>\n",
       "      <td>Splenectomy</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>GENERAL SURGERIES</td>\n",
       "      <td>17</td>\n",
       "      <td>Radical Mastectomy</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>GENERAL SURGERIES</td>\n",
       "      <td>18</td>\n",
       "      <td>Salivary Cyst Ex</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>GENERAL SURGERIES</td>\n",
       "      <td>19</td>\n",
       "      <td>Tail Dock-Amputation</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ProcedureType  ProcedureSubCode           Description  Price\n",
       "0         OFFICE FEES                 1           Office Call     32\n",
       "1         OFFICE FEES                 2             Emergency    100\n",
       "2         OFFICE FEES                 3                  Reck     24\n",
       "3            GROOMING                 1                  Bath     15\n",
       "4            GROOMING                 2              Flea Dip     15\n",
       "5            GROOMING                 3            Flea Spray     10\n",
       "6        VACCINATIONS                 1       Galaxie (DHLPP)     15\n",
       "7        VACCINATIONS                 2              Leukemia     20\n",
       "8        VACCINATIONS                 3                  Lyme     15\n",
       "9        VACCINATIONS                 4                   PCR     15\n",
       "10       VACCINATIONS                 5                Rabies     10\n",
       "11       VACCINATIONS                 6            Bordetella     10\n",
       "12    HOSPITALIZATION                 1   All Hospitalization     25\n",
       "13         ORTHOPEDIC                 1  Amput. per lim thor.    400\n",
       "14         ORTHOPEDIC                 2               Casting     97\n",
       "15         ORTHOPEDIC                 3            Re-Casting     62\n",
       "16         ORTHOPEDIC                 4      Fem. head Ostec.    420\n",
       "17         ORTHOPEDIC                 5     Lx Patella Repair    305\n",
       "18         ORTHOPEDIC                 6      Metamason Splint     50\n",
       "19         ORTHOPEDIC                 7          Pinning-I.M.    325\n",
       "20         ORTHOPEDIC                 8           Pin Removal     68\n",
       "21         ORTHOPEDIC                 9          Cast Removal     40\n",
       "22  GENERAL SURGERIES                 1       Anal Gland Caut    150\n",
       "23  GENERAL SURGERIES                 2        Aural Hematoma    108\n",
       "24  GENERAL SURGERIES                 3                Declaw    125\n",
       "25  GENERAL SURGERIES                 4    Dissolvable Suture     15\n",
       "26  GENERAL SURGERIES                 5              Ear Crop    350\n",
       "27  GENERAL SURGERIES                 6       Gastric Torsion    450\n",
       "28  GENERAL SURGERIES                 7                Hernia    390\n",
       "29  GENERAL SURGERIES                 8             Umbilical    175\n",
       "30  GENERAL SURGERIES                 9              Perineal    375\n",
       "31  GENERAL SURGERIES                10       Unilat Inquinal    195\n",
       "32  GENERAL SURGERIES                11       Intestinal Anas    775\n",
       "33  GENERAL SURGERIES                12    Open Chest Surgery    500\n",
       "34  GENERAL SURGERIES                13      Perineal Adenoma    175\n",
       "35  GENERAL SURGERIES                14     Peritoneal Lavage     85\n",
       "36  GENERAL SURGERIES                15      Pyloric Stenosis    425\n",
       "37  GENERAL SURGERIES                16           Splenectomy    375\n",
       "38  GENERAL SURGERIES                17    Radical Mastectomy    450\n",
       "39  GENERAL SURGERIES                18      Salivary Cyst Ex    570\n",
       "40  GENERAL SURGERIES                19  Tail Dock-Amputation    250"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "procedure_detail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! You're done!\n",
    "\n",
    "* Submit the lab on Gradescope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
