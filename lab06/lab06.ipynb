{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSC 80: Lab 06\n",
    "\n",
    "### Due Date: Saturday November 14th, 11:59 PM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "Much like in DSC 10, this Jupyter Notebook contains the statements of the problems and provides code and markdown cells to display your answers to the problems. Unlike DSC 10, the notebook is *only* for displaying a readable version of your final answers. The coding work will be developed in an accompanying `lab*.py` file, that will be imported into the current notebook.\n",
    "\n",
    "Labs and programming assignments will be graded in (at most) two ways:\n",
    "1. The functions and classes in the accompanying python file will be tested (a la DSC 20),\n",
    "2. The notebook will be graded (for graphs and free response questions).\n",
    "\n",
    "**Do not change the function names in the `*.py` file**\n",
    "- The functions in the `*.py` file are how your assignment is graded, and they are graded by their name. The dictionary at the end of the file (`GRADED FUNCTIONS`) contains the \"grading list\". The final function in the file allows your doctests to check that all the necessary functions exist.\n",
    "- If you changed something you weren't supposed to, just use git to revert!\n",
    "\n",
    "**Tips for working in the Notebook**:\n",
    "- The notebooks serve to present you the questions and give you a place to present your results for later review.\n",
    "- The notebook on *lab assignments* are not graded (only the `.py` file).\n",
    "- Notebooks for PAs will serve as a final report for the assignment, and contain conclusions and answers to open ended questions that are graded.\n",
    "- The notebook serves as a nice environment for 'pre-development' and experimentation before designing your function in your `.py` file.\n",
    "\n",
    "**Tips for developing in the .py file**:\n",
    "- Do not change the function names in the starter code; grading is done using these function names.\n",
    "- Do not change the docstrings in the functions. These are there to tell you if your work is on the right track!\n",
    "- You are encouraged to write your own additional functions to solve the lab! \n",
    "    - Developing in python usually consists of larger files, with many short functions.\n",
    "    - You may write your other functions in an additional `.py` file that you import in `lab**.py` (much like we do in the notebook).\n",
    "- Always document your code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing code from `lab**.py`\n",
    "\n",
    "* We import our `.py` file that's contained in the same directory as this notebook.\n",
    "* We use the `autoreload` notebook extension to make changes to our `lab**.py` file immediately available in our notebook. Without this extension, we would need to restart the notebook kernel to see any changes to `lab**.py` in the notebook.\n",
    "    - `autoreload` is necessary because, upon import, `lab**.py` is compiled to bytecode (in the directory `__pycache__`). Subsequent imports of `lab**` merely import the existing compiled python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lab06 as lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic HTML tags practice\n",
    "\n",
    "**Question 1**\n",
    "\n",
    "Create a very basic `html` file that satisfies the following properties:\n",
    "\n",
    "1. Has `<head>` and `<body>` tags.\n",
    "2. Has a title\n",
    "3. Inside the body tags:\n",
    "    * At least two headers\n",
    "    * At least three images:\n",
    "        * At least one image must be a local file;\n",
    "        * At least one image must be linked to online source; \n",
    "        * At least one image has to have default text when it cannot be displayed.\n",
    "    * At least three references (hyperlinks) to different web pages;\n",
    "    * At least one table with two columns.\n",
    "    \n",
    "        \n",
    "   \n",
    "4. Save your work as `lab06_1.html` in the same directory as `lab06.py`, make sure it loads in the browser and do not forget to submit it.\n",
    "5. **Do not forget to submit all data files needed to display your page.**\n",
    "\n",
    "**Note:** You can toy with (basic) HTML in the cells of a notebook, using either a \"markdown cell\" or by using the `IPython.display.HTML` function. However, be sure to open your saved file in a browser to be sure the page displays properly!\n",
    "\n",
    "**Note:** If you work within Jupyter Notebook, you can later copy your text into a text editor and save it with the .html extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question1():\n",
    "    \"\"\"\n",
    "    NOTE: You do NOT need to do anything with this function.\n",
    "\n",
    "    The function for this question makes sure you\n",
    "    have a correctly named HTML file in the right\n",
    "    place. Note: This does NOT check if the supplementary files\n",
    "    needed for your page are there!\n",
    "\n",
    "    >>> os.path.exists('lab06_1.html')\n",
    "    True\n",
    "    \"\"\"\n",
    "\n",
    "    # Don't change this function body!\n",
    "    # No python required; create the HTML file.\n",
    "    text = '''\n",
    "    <html>\n",
    "        <head>\n",
    "            <title>lab06_1</title>\n",
    "        </head>\n",
    "        <body>\n",
    "            <h1>Surfing</h1>\n",
    "            <img src = \"data/surf_photo.jpg\" alt = 'surf_photo'>\n",
    "            <p> How to Surf\n",
    "                <br>\n",
    "                <a href = \"https://www.youtube.com/watch?v=67QNw2xQlsk\">learn to surf!</a>\n",
    "            </p>\n",
    "                <p>Surfing for the views\n",
    "                    <img src = \"data/sunset.JPG\" alt = 'sunset'>\n",
    "                </p>\n",
    "            <h2>Learn How to Shred!</h2>\n",
    "                <p>\n",
    "                <a href = 'https://www.wikihow.com/Surf'>Steps to Surf</a>\n",
    "                </p>\n",
    "                <p>Look like Kelly Slater after basic steps!\n",
    "                    <img src = \"https://cdn1.theinertia.com/wp-content/uploads/2018/12/kelly4-670x357.jpg\"' alt = 'Kelly Slater Pic'>\n",
    "                </p>\n",
    "                <p>How to be a pro in San Diego\n",
    "                    <br>\n",
    "                    <a href = 'https://www.sandiego.org/articles/surfing/mele-sailis-surf-faves.aspx'>Pro Surf Guide</a>\n",
    "                    \n",
    "        <h2>San Diego Surf Spot Ratings by Max Levitt</h2>\n",
    "\n",
    "        <table style=\"width:100%\">\n",
    "          <tr>\n",
    "            <th>Beach</th>\n",
    "            <th>Rating</th> \n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>Blacks</td>\n",
    "            <td>4</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>Scripps</td>\n",
    "            <td>5</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>La Jolla Shores</td>\n",
    "            <td>3</td>\n",
    "          </tr>\n",
    "          <tr>\n",
    "            <td>Pacific Beach</td>\n",
    "            <td>4</td>\n",
    "          </tr>\n",
    "        </table>\n",
    "        </body>\n",
    "    </html>\n",
    "    '''\n",
    "    file = open(\"lab06_1.html\",\"w\")\n",
    "    file.write(text)\n",
    "    file.close()\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question1()\n",
    "os.path.exists('lab06_1.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'HTML' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-359-f9e14e484b81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mHTML\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'lab06_1.html'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'HTML' is not defined"
     ]
    }
   ],
   "source": [
    "HTML('lab06_1.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <html>\n",
       "        <head>\n",
       "            <title>Lab06</title>\n",
       "        </head>\n",
       "        <body>\n",
       "            <h1>Surfing</h1>\n",
       "            <img src = \"data/surf_photo.jpg\" alt = 'surf_photo'>\n",
       "            <p> How to Surf\n",
       "                <br>\n",
       "                <a href = \"https://www.youtube.com/watch?v=67QNw2xQlsk\">learn to surf!</a>\n",
       "            </p>\n",
       "                <p>Surfing for the views\n",
       "                    <img src = \"data/sunset.JPG\" alt = 'sunset'>\n",
       "                </p>\n",
       "            <h2>Learn How to Shred!</h2>\n",
       "                <p>\n",
       "                <a href = 'https://www.wikihow.com/Surf'>Steps to Surf</a>\n",
       "                </p>\n",
       "                <p>Look like Kelly Slater after basic steps!\n",
       "                    <img src = \"https://cdn1.theinertia.com/wp-content/uploads/2018/12/kelly4-670x357.jpg\"' alt = 'Kelly Slater Pic'>\n",
       "                </p>\n",
       "                <p>How to be a pro in San Diego\n",
       "                    <br>\n",
       "                    <a href = 'https://www.sandiego.org/articles/surfing/mele-sailis-surf-faves.aspx'>Pro Surf Guide</a>\n",
       "                    \n",
       "        <h2>San Diego Surf Spot Ratings by Max Levitt</h2>\n",
       "\n",
       "        <table style=\"width:100%\">\n",
       "          <tr>\n",
       "            <th>Beach</th>\n",
       "            <th>Rating</th> \n",
       "          </tr>\n",
       "          <tr>\n",
       "            <td>Blacks</td>\n",
       "            <td>4</td>\n",
       "          </tr>\n",
       "          <tr>\n",
       "            <td>Scripps</td>\n",
       "            <td>5</td>\n",
       "          </tr>\n",
       "          <tr>\n",
       "            <td>La Jolla Shores</td>\n",
       "            <td>3</td>\n",
       "          </tr>\n",
       "          <tr>\n",
       "            <td>Pacific Beach</td>\n",
       "            <td>4</td>\n",
       "          </tr>\n",
       "        </table>\n",
       "        </body>\n",
       "    </html>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IPython.display.HTML('lab06_1.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping an Online Bookstore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2**\n",
    "\n",
    "Browse through the following fake on-line bookstore: http://books.toscrape.com/. This website is meant for toying with scraping.\n",
    "\n",
    "Scrape the website, collecting data on all books that have **at least a four-star rating**, with a price **under £50** and belong to the book categories you want. You should collect the data in a dataframe as below (if you get an encoding error on your prices columns, like you see in the table below, don't worry about it):\n",
    "<img src=\"bookdata.png\">\n",
    "\n",
    "\n",
    "Do this using the following steps:\n",
    "1. Create a function `extract_book_links` that takes in the content of a book-listing page (a string of html), and returns a list of urls of book-detail pages that satisfy the requirements on \"*at least* a four-star rating, and prices are *under* £50\". \n",
    "\n",
    "2. Create a function `get_product_info` that takes in the content of a book-detail page (a string of html), a variable `categories` that is a list of book categories you want. If this input book is in the categories you want, returns a dictionary corresponding to a row in the dataframe in the image above (where the keys are the column names and the values are the row values); else, skip this book since this is not the book you want (ie. return None).\n",
    "\n",
    "3. Create a function `scrape_books` of a single variable `k` that scrapes the first `k` pages of the bookstore (as determined by starting at the url above and clicking on the 'next' button),a variable `categories` that is a list of book categories you want, and returns a dataframe of books as the picture above. (Note: make sure the books returned satisfy the requirements set in part 1 about rating and price).\n",
    "\n",
    "\n",
    "*Note:* Your function should take under 180 seconds to run through the entire bookstore.\n",
    "\n",
    "*Note:* Don't worry about type casting (ie changing number of reviews to an int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = os.path.join('data', 'products.html')\n",
    "text = open(fp, encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_book_links(text):\n",
    "    \"\"\"\n",
    "    :Example:\n",
    "    >>> fp = os.path.join('data', 'products.html')\n",
    "    >>> out = extract_book_links(open(fp, encoding='utf-8').read())\n",
    "    >>> url = 'scarlet-the-lunar-chronicles-2_218/index.html'\n",
    "    >>> out[1] == url\n",
    "    True\n",
    "    \"\"\"\n",
    "    data = bs4.BeautifulSoup(text, features=\"html.parser\")\n",
    "    cleaned = data.find_all(\"article\", attrs={\"class\": \"product_pod\"})\n",
    "    ratings = []\n",
    "    for x in cleaned:\n",
    "        if x.find(\"p\", attrs={\"class\": \"star-rating Four\"}) or x.find(\"p\", attrs={\"class\": \"star-rating Five\"}):\n",
    "            temp = float(list(map(str.isdigit,x.find(\"p\", attrs={\"class\": \"price_color\"}).text[1:]))[0])\n",
    "            if temp < 50:\n",
    "                ratings.append(x.find(\"a\").get(\"href\"))\n",
    "    return ratings\n",
    "\n",
    "\n",
    "def get_product_info(text, categories):\n",
    "    \"\"\"\n",
    "    :Example:\n",
    "    >>> fp = os.path.join('data', 'Frankenstein.html')\n",
    "    >>> out = get_product_info(open(fp, encoding='utf-8').read(), ['Default'])\n",
    "    >>> isinstance(out, dict)\n",
    "    True\n",
    "    >>> 'Category' in out.keys()\n",
    "    True\n",
    "    >>> out['Rating']\n",
    "    'Two'\n",
    "    \"\"\"\n",
    "    data = bs4.BeautifulSoup(text, features=\"html.parser\")\n",
    "    cat = []\n",
    "    for x in data.find(\"ul\", attrs={\"class\": \"breadcrumb\"}):\n",
    "        cat.append(x)\n",
    "    cat = cat[5].text.strip()\n",
    "    if cat in categories:\n",
    "        tbl = data.find(\"table\", attrs={\"class\": \"table table-striped\"})\n",
    "        vals = tbl.find_all([\"th\", \"td\"])\n",
    "        end_vals = []\n",
    "        for x in vals:\n",
    "            end_vals.append(x.text)\n",
    "        dict = {\"Availability\": end_vals[11],\"Category\": cat,\"Description\": data.find_all(\"p\")[3].text,\"Number of reviews\": end_vals[13],\n",
    "                \"Price (excl. tax)\": end_vals[5],\"Price (incl. tax)\": end_vals[7],\"Product Type\": end_vals[3],\"Rating\": data.find_all(\"p\")[2].attrs.get(\"class\")[1],\n",
    "                \"Tax\": end_vals[9],\"Title\": data.find(\"li\", attrs={\"class\": \"active\"}).text,\"UPC\": end_vals[1]}\n",
    "        return dict\n",
    "    return None\n",
    "\n",
    "\n",
    "def scrape_books(k, categories):\n",
    "    \"\"\"\n",
    "    :param k: number of book-listing pages to scrape.\n",
    "    :returns: a dataframe of information on (certain) books\n",
    "    on the k pages (as described in the question).\n",
    "\n",
    "    :Example:\n",
    "    >>> out = scrape_books(1, ['Mystery'])\n",
    "    >>> out.shape\n",
    "    (1, 11)\n",
    "    >>> out['Rating'][0] == 'Four'\n",
    "    True\n",
    "    >>> out['Title'][0] == 'Sharp Objects'\n",
    "    True\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame()\n",
    "    for page in np.arange(1, k + 1):\n",
    "        books = extract_book_links(requests.get(\"http://books.toscrape.com/catalogue/page-%d.html\" % page).text)\n",
    "        for book in books:\n",
    "            book_info = get_product_info(requests.get(\"http://books.toscrape.com/catalogue/\" + book).text, categories)\n",
    "            if book_info != None:\n",
    "                df = df.append(book_info, ignore_index=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = scrape_books(1, ['Mystery'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Availability</th>\n",
       "      <th>Category</th>\n",
       "      <th>Description</th>\n",
       "      <th>Number of reviews</th>\n",
       "      <th>Price (excl. tax)</th>\n",
       "      <th>Price (incl. tax)</th>\n",
       "      <th>Product Type</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Tax</th>\n",
       "      <th>Title</th>\n",
       "      <th>UPC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In stock (20 available)</td>\n",
       "      <td>Mystery</td>\n",
       "      <td>WICKED above her hipbone, GIRL across her hear...</td>\n",
       "      <td>0</td>\n",
       "      <td>Â£47.82</td>\n",
       "      <td>Â£47.82</td>\n",
       "      <td>Books</td>\n",
       "      <td>Four</td>\n",
       "      <td>Â£0.00</td>\n",
       "      <td>Sharp Objects</td>\n",
       "      <td>e00eb4fd7b871a48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Availability Category  \\\n",
       "0  In stock (20 available)  Mystery   \n",
       "\n",
       "                                         Description Number of reviews  \\\n",
       "0  WICKED above her hipbone, GIRL across her hear...                 0   \n",
       "\n",
       "  Price (excl. tax) Price (incl. tax) Product Type Rating     Tax  \\\n",
       "0           Â£47.82           Â£47.82        Books   Four  Â£0.00   \n",
       "\n",
       "           Title               UPC  \n",
       "0  Sharp Objects  e00eb4fd7b871a48  "
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Availability': 'In stock (1 available)',\n",
       " 'Category': 'Default',\n",
       " 'Description': \"Mary Shelley began writing Frankenstein when she was only eighteen. At once a Gothic thriller, a passionate romance, and a cautionary tale about the dangers of science, Frankenstein tells the story of committed science student Victor Frankenstein. Obsessed with discovering the cause of generation and life and bestowing animation upon lifeless matter, Frankenstein assembles Mary Shelley began writing Frankenstein when she was only eighteen. At once a Gothic thriller, a passionate romance, and a cautionary tale about the dangers of science, Frankenstein tells the story of committed science student Victor Frankenstein. Obsessed with discovering the cause of generation and life and bestowing animation upon lifeless matter, Frankenstein assembles a human being from stolen body parts but; upon bringing it to life, he recoils in horror at the creature's hideousness. Tormented by isolation and loneliness, the once-innocent creature turns to evil and unleashes a campaign of murderous revenge against his creator, Frankenstein.Frankenstein, an instant bestseller and an important ancestor of both the horror and science fiction genres, not only tells a terrifying story, but also raises profound, disturbing questions about the very nature of life and the place of humankind within the cosmos: What does it mean to be human? What responsibilities do we have to each other? How far can we go in tampering with Nature? In our age, filled with news of organ donation genetic engineering, and bio-terrorism, these questions are more relevant than ever. ...more\",\n",
       " 'Number of reviews': '0',\n",
       " 'Price (excl. tax)': '£38.00',\n",
       " 'Price (incl. tax)': '£38.00',\n",
       " 'Product Type': 'Books',\n",
       " 'Rating': 'Two',\n",
       " 'Tax': '£0.00',\n",
       " 'Title': 'Frankenstein',\n",
       " 'UPC': 'a492f49a3e2b6a71'}"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = os.path.join('data', 'Frankenstein.html')\n",
    "out = get_product_info(open(fp, encoding='utf-8').read(), ['Default'])\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.6\n",
      "14.57\n",
      "21.57\n",
      "12.91\n",
      "41.67\n",
      "19.07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['seven-brief-lessons-on-physics_219/index.html',\n",
       " 'scarlet-the-lunar-chronicles-2_218/index.html',\n",
       " 'saga-volume-3-saga-collected-editions-3_216/index.html',\n",
       " 'running-with-scissors_215/index.html',\n",
       " 'rise-of-the-rocket-girls-the-women-who-propelled-us-from-missiles-to-the-moon-to-mars_213/index.html',\n",
       " 'ready-player-one_209/index.html']"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = os.path.join('data', 'products.html')\n",
    "out = extract_book_links(open(fp, encoding='utf-8').read())\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Requests\n",
    "**Question 3**\n",
    "\n",
    "You trade stocks as a hobby. As an avid pandas coder, you figured it is best to calculate some statistics by pulling data from a public API (https://financialmodelingprep.com/developer/docs/#Stock-Historical-Price). Specifically, \"Historical price with change and volume interval\".\n",
    "\n",
    "Some definitions (these are the ones you need to know):\n",
    "- open: The opening price of a stock at the beginning of a trading day\n",
    "- close: The closing price of a stock at the end of a trading day\n",
    "- volume: The total number of shares being traded in a day\n",
    "- percent change: difference in price with respect to the original price (in percentages)\n",
    "\n",
    "\n",
    "1. Create a function `stock_history` which takes in the stock code (`ticker`) as a string, `year` and `month` as integers, and return a dataframe which has the price history for that stock in that month (include all columns).\n",
    "\n",
    "2. Create a function `stock_stats` that takes in the output dataframe from `stock_history` and output the stock price change as a percentage and a rough total transaction volume **in billion dollars** for that month. Assume that on average, shares are traded at the midpoint price of high and low for that day. Return these two values as a tuple in a readable format: reserve 2 decimal points for both values and add a plus or minus sign at the front of the percent change. \n",
    "$$ \\text{Total Transaction Volume (in dollars)} = \\text{Volume (number of shares traded)} \\times \\text{Price} $$\n",
    "\n",
    "*Example*: If \\\\$BYND opens at \\\\$80 and closes at \\\\$120 with a volume of 1 million, its percent change for the day is $(\\$120-\\$80) \\div \\$80 = +50.00\\%$. And the estimated total transaction volume is: $(\\$80+\\$120) / 2 \\times 10^6 = 0.10\\text{B}$.\n",
    "\n",
    "\n",
    "Hint: [pd.date_range](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.date_range.html), \n",
    "\n",
    "*Note:* Make sure you read the API documentation if you get stuck!\n",
    "\n",
    "*Note 2:* In order to make successful requests, you will need an API key. In order to get one, you will need to sign up to the website. Once signed up, you can use the API key that comes with the free plan. It has a limit of 250 requests per day, which should be more than enough. In the code below, replace `your_key` when making requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_endpoint = 'https://financialmodelingprep.com/api/v3/historical-price-full/{}?apikey=298a6bfcbbf37a8725002f1da9404cb9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_history(ticker, year, month):\n",
    "    \"\"\"\n",
    "    Given a stock code and month, return the stock price details for that month\n",
    "    as a dataframe\n",
    "\n",
    "    >>> history = stock_history('BYND', 2019, 6)\n",
    "    >>> history.shape == (20, 13)\n",
    "    True\n",
    "    >>> history.label.iloc[-1]\n",
    "    'June 03, 19'\n",
    "    \"\"\"\n",
    "    stock_endpoint = 'https://financialmodelingprep.com/api/v3/historical-price-full/{}?apikey=298a6bfcbbf37a8725002f1da9404cb9'\n",
    "    start_date = datetime.datetime(year,month,1)\n",
    "    if month == 12:\n",
    "        end_date = datetime.datetime(year + 1,1,1)\n",
    "    else:\n",
    "        end_date = datetime.datetime(year,month + 1,1)\n",
    "    date = pd.date_range(start = start_date, end = end_date)\n",
    "    data = requests.get(stock_endpoint.format(ticker)).json()['historical']\n",
    "    df = pd.DataFrame.from_dict(data)\n",
    "    params={'from': date[0].strftime('%Y-%m-%d'), 'to': date[-1].strftime('%Y-%m-%d')}\n",
    "    out = df[(df['date'] >= params['from']) & (df['date'] < params['to'])]\n",
    "    return out\n",
    "\n",
    "\n",
    "def stock_stats(history):\n",
    "    #rows daily stock prices\n",
    "    #columns: price at open, price at close, high, low, volume\n",
    "    #price change as percentage between open of first day and last day of month\n",
    "    #for every row find mean price which is avg of high and low and multiply by volume to get series of values and sum them to get total volume\n",
    "    \"\"\"\n",
    "    Given a stock's trade history, return the percent change and transactions\n",
    "    in billion dollars.\n",
    "\n",
    "    >>> history = stock_history('BYND', 2019, 6)\n",
    "    >>> stats = stock_stats(history)\n",
    "    >>> len(stats[0]), len(stats[1])\n",
    "    (7, 6)\n",
    "    >>> float(stats[0][1:-1]) > 30\n",
    "    True\n",
    "    >>> float(stats[1][:-1]) > 1\n",
    "    True\n",
    "    \"\"\"\n",
    "    def tot_tran_vol(row):\n",
    "        return (row['high']+row['low']) / (2*row['volume'])\n",
    "    total = str(history.apply(tot_tran_vol, axis = 1).sum()) + 'B'\n",
    "    close = history.iloc[0]['close']\n",
    "    ope = history.iloc[-1]['open']\n",
    "    percent_change =  round(((close - ope) / ope) *100, 2) \n",
    "    if percent_change >= 0:\n",
    "        percent_change = '+'+str(percent_change)+'%'\n",
    "    else:\n",
    "        percent_change = '-'+str(percent_change)+'%'\n",
    "    return tuple([percent_change, total])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('+54.29%', '0.0003269102788063705B')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AAPL?from=2018-03-12&to=2019-03-12\n",
    "history = stock_history('BYND', 2019, 6)\n",
    "stats = stock_stats(history)\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjClose</th>\n",
       "      <th>volume</th>\n",
       "      <th>unadjustedVolume</th>\n",
       "      <th>change</th>\n",
       "      <th>changePercent</th>\n",
       "      <th>vwap</th>\n",
       "      <th>label</th>\n",
       "      <th>changeOverTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>2019-06-28</td>\n",
       "      <td>165.30</td>\n",
       "      <td>168.80</td>\n",
       "      <td>159.550</td>\n",
       "      <td>160.68</td>\n",
       "      <td>160.68</td>\n",
       "      <td>7315300.0</td>\n",
       "      <td>7315300.0</td>\n",
       "      <td>-4.62</td>\n",
       "      <td>-2.795</td>\n",
       "      <td>163.01000</td>\n",
       "      <td>June 28, 19</td>\n",
       "      <td>-0.02795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>2019-06-27</td>\n",
       "      <td>157.31</td>\n",
       "      <td>164.79</td>\n",
       "      <td>155.450</td>\n",
       "      <td>162.91</td>\n",
       "      <td>162.91</td>\n",
       "      <td>5731400.0</td>\n",
       "      <td>5731400.0</td>\n",
       "      <td>5.60</td>\n",
       "      <td>3.560</td>\n",
       "      <td>161.05000</td>\n",
       "      <td>June 27, 19</td>\n",
       "      <td>0.03560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>2019-06-26</td>\n",
       "      <td>160.10</td>\n",
       "      <td>162.25</td>\n",
       "      <td>153.020</td>\n",
       "      <td>160.48</td>\n",
       "      <td>160.48</td>\n",
       "      <td>6378600.0</td>\n",
       "      <td>6378600.0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.237</td>\n",
       "      <td>158.58333</td>\n",
       "      <td>June 26, 19</td>\n",
       "      <td>0.00237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>2019-06-25</td>\n",
       "      <td>138.50</td>\n",
       "      <td>150.69</td>\n",
       "      <td>138.343</td>\n",
       "      <td>150.60</td>\n",
       "      <td>150.60</td>\n",
       "      <td>6632500.0</td>\n",
       "      <td>6632500.0</td>\n",
       "      <td>12.10</td>\n",
       "      <td>8.736</td>\n",
       "      <td>146.54433</td>\n",
       "      <td>June 25, 19</td>\n",
       "      <td>0.08736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>2019-06-24</td>\n",
       "      <td>151.88</td>\n",
       "      <td>152.70</td>\n",
       "      <td>138.000</td>\n",
       "      <td>140.99</td>\n",
       "      <td>140.99</td>\n",
       "      <td>6538500.0</td>\n",
       "      <td>6538500.0</td>\n",
       "      <td>-10.89</td>\n",
       "      <td>-7.170</td>\n",
       "      <td>143.89667</td>\n",
       "      <td>June 24, 19</td>\n",
       "      <td>-0.07170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>2019-06-21</td>\n",
       "      <td>153.54</td>\n",
       "      <td>161.79</td>\n",
       "      <td>150.000</td>\n",
       "      <td>154.13</td>\n",
       "      <td>154.13</td>\n",
       "      <td>7474600.0</td>\n",
       "      <td>7474600.0</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.384</td>\n",
       "      <td>155.30667</td>\n",
       "      <td>June 21, 19</td>\n",
       "      <td>0.00384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>2019-06-20</td>\n",
       "      <td>173.00</td>\n",
       "      <td>174.00</td>\n",
       "      <td>163.300</td>\n",
       "      <td>165.17</td>\n",
       "      <td>165.17</td>\n",
       "      <td>6660500.0</td>\n",
       "      <td>6660500.0</td>\n",
       "      <td>-7.83</td>\n",
       "      <td>-4.526</td>\n",
       "      <td>167.49000</td>\n",
       "      <td>June 20, 19</td>\n",
       "      <td>-0.04526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>2019-06-19</td>\n",
       "      <td>171.37</td>\n",
       "      <td>174.45</td>\n",
       "      <td>162.250</td>\n",
       "      <td>169.28</td>\n",
       "      <td>169.28</td>\n",
       "      <td>9452000.0</td>\n",
       "      <td>9452000.0</td>\n",
       "      <td>-2.09</td>\n",
       "      <td>-1.220</td>\n",
       "      <td>168.66000</td>\n",
       "      <td>June 19, 19</td>\n",
       "      <td>-0.01220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>2019-06-18</td>\n",
       "      <td>200.00</td>\n",
       "      <td>201.88</td>\n",
       "      <td>160.700</td>\n",
       "      <td>169.89</td>\n",
       "      <td>169.89</td>\n",
       "      <td>23966900.0</td>\n",
       "      <td>23966900.0</td>\n",
       "      <td>-30.11</td>\n",
       "      <td>-15.055</td>\n",
       "      <td>177.49000</td>\n",
       "      <td>June 18, 19</td>\n",
       "      <td>-0.15055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>2019-06-17</td>\n",
       "      <td>163.18</td>\n",
       "      <td>171.19</td>\n",
       "      <td>160.611</td>\n",
       "      <td>169.96</td>\n",
       "      <td>169.96</td>\n",
       "      <td>14626700.0</td>\n",
       "      <td>14626700.0</td>\n",
       "      <td>6.78</td>\n",
       "      <td>4.155</td>\n",
       "      <td>167.25367</td>\n",
       "      <td>June 17, 19</td>\n",
       "      <td>0.04155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>2019-06-14</td>\n",
       "      <td>142.01</td>\n",
       "      <td>157.90</td>\n",
       "      <td>141.800</td>\n",
       "      <td>151.48</td>\n",
       "      <td>151.48</td>\n",
       "      <td>14964600.0</td>\n",
       "      <td>14964600.0</td>\n",
       "      <td>9.47</td>\n",
       "      <td>6.669</td>\n",
       "      <td>150.39333</td>\n",
       "      <td>June 14, 19</td>\n",
       "      <td>0.06669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>2019-06-13</td>\n",
       "      <td>141.52</td>\n",
       "      <td>146.45</td>\n",
       "      <td>134.250</td>\n",
       "      <td>141.39</td>\n",
       "      <td>141.39</td>\n",
       "      <td>9474600.0</td>\n",
       "      <td>9474600.0</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>140.69667</td>\n",
       "      <td>June 13, 19</td>\n",
       "      <td>-0.00092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>2019-06-12</td>\n",
       "      <td>133.99</td>\n",
       "      <td>150.45</td>\n",
       "      <td>131.563</td>\n",
       "      <td>141.97</td>\n",
       "      <td>141.97</td>\n",
       "      <td>16879500.0</td>\n",
       "      <td>16879500.0</td>\n",
       "      <td>7.98</td>\n",
       "      <td>5.956</td>\n",
       "      <td>141.32767</td>\n",
       "      <td>June 12, 19</td>\n",
       "      <td>0.05956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>2019-06-11</td>\n",
       "      <td>145.25</td>\n",
       "      <td>150.00</td>\n",
       "      <td>125.230</td>\n",
       "      <td>126.04</td>\n",
       "      <td>126.04</td>\n",
       "      <td>15516000.0</td>\n",
       "      <td>15516000.0</td>\n",
       "      <td>-19.21</td>\n",
       "      <td>-13.225</td>\n",
       "      <td>133.75667</td>\n",
       "      <td>June 11, 19</td>\n",
       "      <td>-0.13225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>155.70</td>\n",
       "      <td>186.43</td>\n",
       "      <td>147.000</td>\n",
       "      <td>168.10</td>\n",
       "      <td>168.10</td>\n",
       "      <td>24986000.0</td>\n",
       "      <td>24986000.0</td>\n",
       "      <td>12.40</td>\n",
       "      <td>7.964</td>\n",
       "      <td>167.17667</td>\n",
       "      <td>June 10, 19</td>\n",
       "      <td>0.07964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>2019-06-07</td>\n",
       "      <td>130.00</td>\n",
       "      <td>149.46</td>\n",
       "      <td>120.760</td>\n",
       "      <td>138.65</td>\n",
       "      <td>138.65</td>\n",
       "      <td>23916700.0</td>\n",
       "      <td>23916700.0</td>\n",
       "      <td>8.65</td>\n",
       "      <td>6.654</td>\n",
       "      <td>136.29000</td>\n",
       "      <td>June 07, 19</td>\n",
       "      <td>0.06654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>2019-06-06</td>\n",
       "      <td>102.00</td>\n",
       "      <td>102.25</td>\n",
       "      <td>98.850</td>\n",
       "      <td>99.50</td>\n",
       "      <td>99.50</td>\n",
       "      <td>6484000.0</td>\n",
       "      <td>6484000.0</td>\n",
       "      <td>-2.50</td>\n",
       "      <td>-2.451</td>\n",
       "      <td>100.20000</td>\n",
       "      <td>June 06, 19</td>\n",
       "      <td>-0.02451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>2019-06-05</td>\n",
       "      <td>105.50</td>\n",
       "      <td>105.50</td>\n",
       "      <td>99.640</td>\n",
       "      <td>102.60</td>\n",
       "      <td>102.60</td>\n",
       "      <td>4283500.0</td>\n",
       "      <td>4283500.0</td>\n",
       "      <td>-2.90</td>\n",
       "      <td>-2.749</td>\n",
       "      <td>102.58000</td>\n",
       "      <td>June 05, 19</td>\n",
       "      <td>-0.02749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>2019-06-04</td>\n",
       "      <td>101.25</td>\n",
       "      <td>103.50</td>\n",
       "      <td>97.820</td>\n",
       "      <td>103.41</td>\n",
       "      <td>103.41</td>\n",
       "      <td>5484900.0</td>\n",
       "      <td>5484900.0</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.133</td>\n",
       "      <td>101.57667</td>\n",
       "      <td>June 04, 19</td>\n",
       "      <td>0.02133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>2019-06-03</td>\n",
       "      <td>104.14</td>\n",
       "      <td>108.67</td>\n",
       "      <td>95.662</td>\n",
       "      <td>96.16</td>\n",
       "      <td>96.16</td>\n",
       "      <td>8027700.0</td>\n",
       "      <td>8027700.0</td>\n",
       "      <td>-7.98</td>\n",
       "      <td>-7.663</td>\n",
       "      <td>100.16400</td>\n",
       "      <td>June 03, 19</td>\n",
       "      <td>-0.07663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date    open    high      low   close  adjClose      volume  \\\n",
       "349  2019-06-28  165.30  168.80  159.550  160.68    160.68   7315300.0   \n",
       "350  2019-06-27  157.31  164.79  155.450  162.91    162.91   5731400.0   \n",
       "351  2019-06-26  160.10  162.25  153.020  160.48    160.48   6378600.0   \n",
       "352  2019-06-25  138.50  150.69  138.343  150.60    150.60   6632500.0   \n",
       "353  2019-06-24  151.88  152.70  138.000  140.99    140.99   6538500.0   \n",
       "354  2019-06-21  153.54  161.79  150.000  154.13    154.13   7474600.0   \n",
       "355  2019-06-20  173.00  174.00  163.300  165.17    165.17   6660500.0   \n",
       "356  2019-06-19  171.37  174.45  162.250  169.28    169.28   9452000.0   \n",
       "357  2019-06-18  200.00  201.88  160.700  169.89    169.89  23966900.0   \n",
       "358  2019-06-17  163.18  171.19  160.611  169.96    169.96  14626700.0   \n",
       "359  2019-06-14  142.01  157.90  141.800  151.48    151.48  14964600.0   \n",
       "360  2019-06-13  141.52  146.45  134.250  141.39    141.39   9474600.0   \n",
       "361  2019-06-12  133.99  150.45  131.563  141.97    141.97  16879500.0   \n",
       "362  2019-06-11  145.25  150.00  125.230  126.04    126.04  15516000.0   \n",
       "363  2019-06-10  155.70  186.43  147.000  168.10    168.10  24986000.0   \n",
       "364  2019-06-07  130.00  149.46  120.760  138.65    138.65  23916700.0   \n",
       "365  2019-06-06  102.00  102.25   98.850   99.50     99.50   6484000.0   \n",
       "366  2019-06-05  105.50  105.50   99.640  102.60    102.60   4283500.0   \n",
       "367  2019-06-04  101.25  103.50   97.820  103.41    103.41   5484900.0   \n",
       "368  2019-06-03  104.14  108.67   95.662   96.16     96.16   8027700.0   \n",
       "\n",
       "     unadjustedVolume  change  changePercent       vwap        label  \\\n",
       "349         7315300.0   -4.62         -2.795  163.01000  June 28, 19   \n",
       "350         5731400.0    5.60          3.560  161.05000  June 27, 19   \n",
       "351         6378600.0    0.38          0.237  158.58333  June 26, 19   \n",
       "352         6632500.0   12.10          8.736  146.54433  June 25, 19   \n",
       "353         6538500.0  -10.89         -7.170  143.89667  June 24, 19   \n",
       "354         7474600.0    0.59          0.384  155.30667  June 21, 19   \n",
       "355         6660500.0   -7.83         -4.526  167.49000  June 20, 19   \n",
       "356         9452000.0   -2.09         -1.220  168.66000  June 19, 19   \n",
       "357        23966900.0  -30.11        -15.055  177.49000  June 18, 19   \n",
       "358        14626700.0    6.78          4.155  167.25367  June 17, 19   \n",
       "359        14964600.0    9.47          6.669  150.39333  June 14, 19   \n",
       "360         9474600.0   -0.13         -0.092  140.69667  June 13, 19   \n",
       "361        16879500.0    7.98          5.956  141.32767  June 12, 19   \n",
       "362        15516000.0  -19.21        -13.225  133.75667  June 11, 19   \n",
       "363        24986000.0   12.40          7.964  167.17667  June 10, 19   \n",
       "364        23916700.0    8.65          6.654  136.29000  June 07, 19   \n",
       "365         6484000.0   -2.50         -2.451  100.20000  June 06, 19   \n",
       "366         4283500.0   -2.90         -2.749  102.58000  June 05, 19   \n",
       "367         5484900.0    2.16          2.133  101.57667  June 04, 19   \n",
       "368         8027700.0   -7.98         -7.663  100.16400  June 03, 19   \n",
       "\n",
       "     changeOverTime  \n",
       "349        -0.02795  \n",
       "350         0.03560  \n",
       "351         0.00237  \n",
       "352         0.08736  \n",
       "353        -0.07170  \n",
       "354         0.00384  \n",
       "355        -0.04526  \n",
       "356        -0.01220  \n",
       "357        -0.15055  \n",
       "358         0.04155  \n",
       "359         0.06669  \n",
       "360        -0.00092  \n",
       "361         0.05956  \n",
       "362        -0.13225  \n",
       "363         0.07964  \n",
       "364         0.06654  \n",
       "365        -0.02451  \n",
       "366        -0.02749  \n",
       "367         0.02133  \n",
       "368        -0.07663  "
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'months' is an invalid keyword argument for __new__()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-152-4ee689c42d0c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdate\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonths\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'months' is an invalid keyword argument for __new__()"
     ]
    }
   ],
   "source": [
    "date = datetime.datetime(2000,12,1)\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comment Threads\n",
    "\n",
    "**Question 4**\n",
    "\n",
    "As a hacker, you get your daily dose of tech news on [Hacker News](https://news.ycombinator.com/). The problem now is that you don't have internet access on your phone in your morning commute to work, so you want to save the interesting stories' comments thread beforehand in a flat file source like csv. You find their API documentation ( https://github.com/HackerNews/API) and implement the following task:\n",
    "\n",
    "1. Write a function `get_comments` that takes `storyid` as a parameter and returns a dataframe of all the comments below the news story. You can ignore 'dead' comments (you will know it when you see it). **Make sure the order of the comments in your dataframe is from top to bottom just as you see on the website**. You are allowed to use loops in this function. Addtional requirement: write at least one helper method\n",
    "\n",
    "You only want these information for the comments:\n",
    "1. `id`: the unique ids\n",
    "2. `by`: the author of the comment\n",
    "3. `parent`: who (also in unique ids) they are replying to\n",
    "4. `text`: the actual comment\n",
    "5. `time`: when the comment is created (in `pd.datetime` format)\n",
    "\n",
    "Hints:\n",
    "1. Use depth-first-search when traversing the comments tree.\n",
    "2. https://docs.python.org/3/tutorial/datastructures.html#using-lists-as-stacks.\n",
    "3. Check the size of your dataframe to the story's `descendants` attribute (number of comments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_endpoint = \"https://hacker-news.firebaseio.com/v0/item/{}.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "pop from empty list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-258-2f09500bc828>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstack\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: pop from empty list"
     ]
    }
   ],
   "source": [
    "stack = []\n",
    "stack.pop()\n",
    "stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments(storyid):\n",
    "    #use stack to add in kids(import)\n",
    "    #add all kids to stack\n",
    "    #pop stack request info and add to dictionary\n",
    "    #add all their kids\n",
    "    #if no kids key then move past\n",
    "    #dead key in dict if there do not add to dictionary \n",
    "    \"\"\"\n",
    "    Returns a dataframe of all the comments below a news story\n",
    "    >>> out = get_comments(18344932)\n",
    "    >>> out.shape\n",
    "    (18, 5)\n",
    "    >>> out.loc[5, 'by']\n",
    "    'RobAtticus'\n",
    "    >>> out.loc[5, 'time'].day\n",
    "    31\n",
    "    \"\"\"\n",
    "    news_endpoint = \"https://hacker-news.firebaseio.com/v0/item/{}.json\"\n",
    "    stack = [storyid]\n",
    "    in_data = requests.get(news_endpoint.format(stack.pop())).json()\n",
    "    if 'kids' in in_data.keys():\n",
    "            for kid in in_data['kids']:\n",
    "                stack.append(kid)\n",
    "    all_data =[]\n",
    "    while len(stack) > 0:\n",
    "        in_data = requests.get(news_endpoint.format(stack.pop())).json()\n",
    "        if 'dead' in in_data.keys():\n",
    "            continue\n",
    "        all_data.append(in_data)\n",
    "        if 'kids' in in_data.keys():\n",
    "            for kid in in_data['kids']:\n",
    "                stack.append(kid)\n",
    "    df = pd.DataFrame(all_data)[['id','by','parent','text','time']]\n",
    "    def convert_time(time):\n",
    "        return pd.to_datetime(time)\n",
    "    df['time'] = df['time'].apply(convert_time)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>by</th>\n",
       "      <th>parent</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18346746</td>\n",
       "      <td>athenot</td>\n",
       "      <td>18344932</td>\n",
       "      <td>It would be nice if they did a quick compariso...</td>\n",
       "      <td>1970-01-01 00:00:01.541001073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18346787</td>\n",
       "      <td>RobAtticus</td>\n",
       "      <td>18346746</td>\n",
       "      <td>We do have comparisons, but judging by their M...</td>\n",
       "      <td>1970-01-01 00:00:01.541001399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18346822</td>\n",
       "      <td>athenot</td>\n",
       "      <td>18346787</td>\n",
       "      <td>Thanks a lot, this is useful for comparing.&lt;p&gt;...</td>\n",
       "      <td>1970-01-01 00:00:01.541001629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18346476</td>\n",
       "      <td>dominotw</td>\n",
       "      <td>18344932</td>\n",
       "      <td>I evaluated this heavily but had to backoff be...</td>\n",
       "      <td>1970-01-01 00:00:01.540999649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18349689</td>\n",
       "      <td>jason_slack</td>\n",
       "      <td>18346476</td>\n",
       "      <td>What were the specs of the machine you were us...</td>\n",
       "      <td>1970-01-01 00:00:01.541024187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18346702</td>\n",
       "      <td>RobAtticus</td>\n",
       "      <td>18346476</td>\n",
       "      <td>Sorry to hear, though I&amp;#x27;d like to mention...</td>\n",
       "      <td>1970-01-01 00:00:01.541000861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18347232</td>\n",
       "      <td>grumpydba</td>\n",
       "      <td>18346702</td>\n",
       "      <td>Hi,&lt;p&gt;are the upcoming clustering efforts deve...</td>\n",
       "      <td>1970-01-01 00:00:01.541004279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18346750</td>\n",
       "      <td>zip1234</td>\n",
       "      <td>18344932</td>\n",
       "      <td>How fast is it when it has a TB of data? I rea...</td>\n",
       "      <td>1970-01-01 00:00:01.541001103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18347555</td>\n",
       "      <td>dominotw</td>\n",
       "      <td>18346750</td>\n",
       "      <td>They have some numbers on their blog. Its very...</td>\n",
       "      <td>1970-01-01 00:00:01.541006374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18347260</td>\n",
       "      <td>nevi-me</td>\n",
       "      <td>18346750</td>\n",
       "      <td>I spent about 8 months writing data to TSDB. I...</td>\n",
       "      <td>1970-01-01 00:00:01.541004454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18348601</td>\n",
       "      <td>sman393</td>\n",
       "      <td>18344932</td>\n",
       "      <td>Can this be used side by side on normal Postgr...</td>\n",
       "      <td>1970-01-01 00:00:01.541014179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18348631</td>\n",
       "      <td>RobAtticus</td>\n",
       "      <td>18348601</td>\n",
       "      <td>Yep, absolutely. Regular PostgreSQL tables coe...</td>\n",
       "      <td>1970-01-01 00:00:01.541014492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18348984</td>\n",
       "      <td>sman393</td>\n",
       "      <td>18348631</td>\n",
       "      <td>Good to hear! how does the current TimescaleDB...</td>\n",
       "      <td>1970-01-01 00:00:01.541017426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18349540</td>\n",
       "      <td>RobAtticus</td>\n",
       "      <td>18348984</td>\n",
       "      <td>Not sure I follow exactly what you&amp;#x27;re ask...</td>\n",
       "      <td>1970-01-01 00:00:01.541022440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>18350673</td>\n",
       "      <td>sman393</td>\n",
       "      <td>18349540</td>\n",
       "      <td>Alright thanks! I thought I read that Timescal...</td>\n",
       "      <td>1970-01-01 00:00:01.541034719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18351061</td>\n",
       "      <td>RobAtticus</td>\n",
       "      <td>18350673</td>\n",
       "      <td>It does not support sharding writes across mul...</td>\n",
       "      <td>1970-01-01 00:00:01.541039703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18346406</td>\n",
       "      <td>msiggy</td>\n",
       "      <td>18344932</td>\n",
       "      <td>I&amp;#x27;m excited to give this database a try i...</td>\n",
       "      <td>1970-01-01 00:00:01.540999222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18380397</td>\n",
       "      <td>valyala</td>\n",
       "      <td>18344932</td>\n",
       "      <td>TimescaleDB is great for storing time series c...</td>\n",
       "      <td>1970-01-01 00:00:01.541400799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id           by    parent  \\\n",
       "0   18346746      athenot  18344932   \n",
       "1   18346787   RobAtticus  18346746   \n",
       "2   18346822      athenot  18346787   \n",
       "3   18346476     dominotw  18344932   \n",
       "4   18349689  jason_slack  18346476   \n",
       "5   18346702   RobAtticus  18346476   \n",
       "6   18347232    grumpydba  18346702   \n",
       "7   18346750      zip1234  18344932   \n",
       "8   18347555     dominotw  18346750   \n",
       "9   18347260      nevi-me  18346750   \n",
       "10  18348601      sman393  18344932   \n",
       "11  18348631   RobAtticus  18348601   \n",
       "12  18348984      sman393  18348631   \n",
       "13  18349540   RobAtticus  18348984   \n",
       "14  18350673      sman393  18349540   \n",
       "15  18351061   RobAtticus  18350673   \n",
       "16  18346406       msiggy  18344932   \n",
       "17  18380397      valyala  18344932   \n",
       "\n",
       "                                                 text  \\\n",
       "0   It would be nice if they did a quick compariso...   \n",
       "1   We do have comparisons, but judging by their M...   \n",
       "2   Thanks a lot, this is useful for comparing.<p>...   \n",
       "3   I evaluated this heavily but had to backoff be...   \n",
       "4   What were the specs of the machine you were us...   \n",
       "5   Sorry to hear, though I&#x27;d like to mention...   \n",
       "6   Hi,<p>are the upcoming clustering efforts deve...   \n",
       "7   How fast is it when it has a TB of data? I rea...   \n",
       "8   They have some numbers on their blog. Its very...   \n",
       "9   I spent about 8 months writing data to TSDB. I...   \n",
       "10  Can this be used side by side on normal Postgr...   \n",
       "11  Yep, absolutely. Regular PostgreSQL tables coe...   \n",
       "12  Good to hear! how does the current TimescaleDB...   \n",
       "13  Not sure I follow exactly what you&#x27;re ask...   \n",
       "14  Alright thanks! I thought I read that Timescal...   \n",
       "15  It does not support sharding writes across mul...   \n",
       "16  I&#x27;m excited to give this database a try i...   \n",
       "17  TimescaleDB is great for storing time series c...   \n",
       "\n",
       "                            time  \n",
       "0  1970-01-01 00:00:01.541001073  \n",
       "1  1970-01-01 00:00:01.541001399  \n",
       "2  1970-01-01 00:00:01.541001629  \n",
       "3  1970-01-01 00:00:01.540999649  \n",
       "4  1970-01-01 00:00:01.541024187  \n",
       "5  1970-01-01 00:00:01.541000861  \n",
       "6  1970-01-01 00:00:01.541004279  \n",
       "7  1970-01-01 00:00:01.541001103  \n",
       "8  1970-01-01 00:00:01.541006374  \n",
       "9  1970-01-01 00:00:01.541004454  \n",
       "10 1970-01-01 00:00:01.541014179  \n",
       "11 1970-01-01 00:00:01.541014492  \n",
       "12 1970-01-01 00:00:01.541017426  \n",
       "13 1970-01-01 00:00:01.541022440  \n",
       "14 1970-01-01 00:00:01.541034719  \n",
       "15 1970-01-01 00:00:01.541039703  \n",
       "16 1970-01-01 00:00:01.540999222  \n",
       "17 1970-01-01 00:00:01.541400799  "
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = get_comments(18344932)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.loc[5, 'time'].day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'by': 'ScottWRobinson',\n",
       " 'descendants': 18,\n",
       " 'id': 18344932,\n",
       " 'kids': [18380397,\n",
       "  18346406,\n",
       "  18348601,\n",
       "  18346750,\n",
       "  18346476,\n",
       "  18346746,\n",
       "  18346388],\n",
       " 'score': 47,\n",
       " 'time': 1540987334,\n",
       " 'title': 'TimescaleDB 1.0 Is Production Ready',\n",
       " 'type': 'story',\n",
       " 'url': 'https://blog.timescale.com/1-0-enterprise-production-ready-time-series-database-open-source-d32395a10cbf'}"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = requests.get(news_endpoint.format(18344932)).json()\n",
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1541400799"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time = requests.get(news_endpoint.format(start['kids'][0])).json()['time']\n",
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "print(data.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! You're done!\n",
    "\n",
    "* Submit the lab on Gradescope"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
